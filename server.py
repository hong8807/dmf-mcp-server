"""
DMF Intelligence Server (MCP + ì¹´ì¹´ì˜¤í†¡ ì±„ë„ ì±—ë´‡)
===================================================
ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ DMF ë°ì´í„°ë¥¼ ì¡°íšŒÂ·ë¶„ì„í•˜ëŠ” í†µí•© ì„œë²„

[1] MCP ì„œë²„: Claude Desktop / PlayMCPì—ì„œ ì‚¬ìš©
[2] ì¹´ì¹´ì˜¤ ì›¹í›… API: ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë” Skill ì„œë²„

ë°°í¬: Render.com â†’ í•˜ë‚˜ì˜ ì„œë²„ë¡œ ë‘ ê¸°ëŠ¥ ëª¨ë‘ ì œê³µ
"""

import os
import json
import tempfile
import logging
import re
from datetime import datetime, timedelta
from collections import Counter
from typing import Optional
from contextlib import asynccontextmanager

import requests
import pandas as pd
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import uvicorn

# MCP (ì¡°ê±´ë¶€ ì„í¬íŠ¸ â€” MCP ì—†ì´ë„ ì¹´ì¹´ì˜¤ ì›¹í›…ë§Œìœ¼ë¡œ ë™ì‘ ê°€ëŠ¥)
try:
    from mcp.server.fastmcp import FastMCP
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë¡œê¹… ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("dmf-server")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë°ì´í„° ìºì‹± (ì¹´ì¹´ì˜¤ 5ì´ˆ íƒ€ì„ì•„ì›ƒ ëŒ€ì‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import threading

_cache = {
    "df": None,           # ìºì‹±ëœ DataFrame
    "last_updated": None, # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°
    "loading": False      # ë¡œë”© ì¤‘ ì—¬ë¶€
}
CACHE_TTL = timedelta(hours=24)  # í•˜ë£¨ 1íšŒ ê°±ì‹ 


def _download_dmf_excel() -> str:
    """ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ì—ì„œ DMF ì—‘ì…€ ë‹¤ìš´ë¡œë“œ â†’ ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    url = "https://nedrug.mfds.go.kr/pbp/CCBAC03/getExcel"
    logger.info("ğŸ“¥ DMF ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    response = requests.get(url, timeout=120)
    response.raise_for_status()

    tmp = tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False)
    tmp.write(response.content)
    tmp.close()
    logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {tmp.name}")
    return tmp.name


def _get_cached_data() -> pd.DataFrame:
    """ìºì‹±ëœ ë°ì´í„° ë°˜í™˜. ì—†ê±°ë‚˜ ë§Œë£Œë˜ë©´ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ."""
    now = datetime.now()

    # ìºì‹œê°€ ìœ íš¨í•˜ë©´ ë°”ë¡œ ë°˜í™˜
    if (_cache["df"] is not None and
        _cache["last_updated"] is not None and
        now - _cache["last_updated"] < CACHE_TTL):
        logger.info("âš¡ ìºì‹œ ë°ì´í„° ì‚¬ìš©")
        return _cache["df"]

    # ìºì‹œ ê°±ì‹ 
    logger.info("ğŸ”„ ìºì‹œ ê°±ì‹  ì¤‘...")
    excel_path = _download_dmf_excel()
    try:
        df = _load_and_prepare(excel_path)
        _cache["df"] = df
        _cache["last_updated"] = now
        logger.info(f"âœ… ìºì‹œ ê°±ì‹  ì™„ë£Œ ({len(df)}ê±´)")
        return df
    finally:
        os.unlink(excel_path)


def _preload_cache():
    """ì„œë²„ ì‹œì‘ ì‹œ ë°±ê·¸ë¼ìš´ë“œë¡œ ìºì‹œ ë¯¸ë¦¬ ë¡œë“œ"""
    try:
        _cache["loading"] = True
        _get_cached_data()
    except Exception as e:
        logger.error(f"âŒ ìºì‹œ í”„ë¦¬ë¡œë“œ ì‹¤íŒ¨: {e}")
    finally:
        _cache["loading"] = False


def _load_and_prepare(excel_path: str) -> pd.DataFrame:
    """ì—‘ì…€ ë¡œë“œ + ê¸°ë³¸ ì „ì²˜ë¦¬"""
    df = pd.read_excel(excel_path)

    # NaN ì²˜ë¦¬ (ë¹ˆ ì¹¸ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜)
    text_cols = ['ì„±ë¶„ëª…', 'ì‹ ì²­ì¸', 'ì œì¡°ì†Œëª…', 'ì œì¡°êµ­ê°€', 'ë“±ë¡ë²ˆí˜¸',
                 'ì·¨ì†Œ/ì·¨í•˜êµ¬ë¶„', 'ì—°ê³„ì‹¬ì‚¬ë¬¸ì„œë²ˆí˜¸']
    for col in text_cols:
        if col in df.columns:
            df[col] = df[col].fillna('')

    df['ìµœì´ˆë“±ë¡ì¼ì'] = pd.to_datetime(df['ìµœì´ˆë“±ë¡ì¼ì'], errors='coerce')

    df['is_í—ˆì—¬'] = df['ë“±ë¡ë²ˆí˜¸'].astype(str).str.contains(r'\(', na=False)
    df['ë“±ë¡ìœ í˜•'] = df['is_í—ˆì—¬'].map({True: 'í—ˆì—¬(ë³€ê²½)', False: 'ìµœì´ˆë“±ë¡'})

    df['base_dmf'] = df['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
        lambda x: x.split('(', 1)[0] if '(' in x else x
    )
    has_linked = (df['ì—°ê³„ì‹¬ì‚¬ë¬¸ì„œë²ˆí˜¸'].astype(str).str.strip() != '')
    linked_bases = set(df.loc[has_linked, 'base_dmf'])
    df['has_ì—°ê³„ì‹¬ì‚¬'] = df['base_dmf'].isin(linked_bases)

    active = df[df['ì·¨ì†Œ/ì·¨í•˜êµ¬ë¶„'] == 'ì •ìƒ'].copy()
    return active


# â”€â”€â”€ ë¶„ì„ í•¨ìˆ˜ë“¤ (JSON dict ë°˜í™˜) â”€â”€â”€

def analyze_weekly_dmf(weeks_ago: int = 1) -> dict:
    """ì£¼ê°„ DMF ë“±ë¡ í˜„í™© ë¶„ì„"""
    try:
        active = _get_cached_data()

        today = datetime.today()
        days_since_monday = today.weekday()
        this_monday = today - timedelta(days=days_since_monday)
        target_monday = this_monday - timedelta(weeks=weeks_ago)
        target_friday = target_monday + timedelta(days=4)

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(target_monday)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(target_friday))
        week_df = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        week_label = f"{target_monday.strftime('%m/%d')}~{target_friday.strftime('%m/%d')}"

        if len(week_df) == 0:
            return {"ê¸°ê°„": week_label, "ë©”ì‹œì§€": "í•´ë‹¹ ì£¼ê°„ ì‹ ê·œ DMF ë“±ë¡ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        details = []
        for _, row in week_df.iterrows():
            details.append({
                "ë“±ë¡ì¼": row['ìµœì´ˆë“±ë¡ì¼ì'].strftime('%m/%d'),
                "ë“±ë¡ìœ í˜•": 'í—ˆì—¬' if row['is_í—ˆì—¬'] else 'ìµœì´ˆ',
                "ì„±ë¶„ëª…": str(row.get('ì„±ë¶„ëª…', '')),
                "ì‹ ì²­ì¸": str(row.get('ì‹ ì²­ì¸', '')),
                "ì œì¡°ì†Œ": str(row.get('ì œì¡°ì†Œëª…', ''))[:25],
                "êµ­ê°€": str(row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/'),
                "ì—°ê³„ì‹¬ì‚¬": 'O' if row['has_ì—°ê³„ì‹¬ì‚¬'] else 'X'
            })

        return {
            "ê¸°ê°„": week_label,
            "ì´ê±´ìˆ˜": len(week_df),
            "ìµœì´ˆë“±ë¡": int((~week_df['is_í—ˆì—¬']).sum()),
            "í—ˆì—¬_ë³€ê²½": int(week_df['is_í—ˆì—¬'].sum()),
            "ì—°ê³„ì‹¬ì‚¬_ìˆìŒ": int(week_df['has_ì—°ê³„ì‹¬ì‚¬'].sum()),
            "ìƒì„¸ë‚´ì—­": details
        }
    except Exception as e:
        logger.error(f"ì£¼ê°„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise


def analyze_monthly_dmf(months_ago: int = 1) -> dict:
    """ì›”ê°„ DMF ë“±ë¡ í˜„í™© ë¶„ì„"""
    try:
        active = _get_cached_data()

        today = datetime.today()
        target_end = today.replace(day=1) - timedelta(days=1)
        for _ in range(months_ago - 1):
            target_end = target_end.replace(day=1) - timedelta(days=1)
        target_start = target_end.replace(day=1)

        month_label = target_start.strftime('%Yë…„ %mì›”')

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(target_start)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(target_end))
        month_df = active[mask]

        prev_end = target_start - timedelta(days=1)
        prev_start = prev_end.replace(day=1)
        prev_mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(prev_start)) & \
                    (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(prev_end))
        prev_count = int(active[prev_mask].shape[0])

        if prev_count > 0:
            change_pct = (len(month_df) - prev_count) / prev_count * 100
            change_str = f"+{change_pct:.1f}%" if change_pct >= 0 else f"{change_pct:.1f}%"
        else:
            change_str = "N/A"

        countries = []
        for c in month_df['ì œì¡°êµ­ê°€'].dropna():
            for cc in str(c).split('@'):
                countries.append(cc.strip())
        country_counts = Counter(countries).most_common(10)
        total_c = sum(dict(country_counts).values()) if country_counts else 1
        country_list = [
            {"êµ­ê°€": c, "ê±´ìˆ˜": n, "ë¹„ìœ¨": f"{n/total_c*100:.1f}%"}
            for c, n in country_counts
        ]

        top_applicants = month_df.groupby('ì‹ ì²­ì¸').agg(
            ê±´ìˆ˜=('ë“±ë¡ë²ˆí˜¸', 'count')
        ).sort_values('ê±´ìˆ˜', ascending=False).head(5)
        applicant_list = [
            {"ì‹ ì²­ì¸": name, "ê±´ìˆ˜": int(row['ê±´ìˆ˜'])}
            for name, row in top_applicants.iterrows()
        ]

        return {
            "ê¸°ê°„": month_label,
            "ì´ê±´ìˆ˜": len(month_df),
            "ìµœì´ˆë“±ë¡": int((~month_df['is_í—ˆì—¬']).sum()),
            "í—ˆì—¬_ë³€ê²½": int(month_df['is_í—ˆì—¬'].sum()),
            "ì „ì›”ëŒ€ë¹„_ë³€ë™": change_str,
            "ì „ì›”_ê±´ìˆ˜": prev_count,
            "êµ­ê°€ë³„_ë¶„í¬": country_list,
            "ì£¼ìš”_ì‹ ì²­ì¸_TOP5": applicant_list
        }
    except Exception as e:
        logger.error(f"ì›”ê°„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise


def search_ingredient(ingredient: str, linked_filter: str = None) -> dict:
    """
    ì„±ë¶„ëª…ìœ¼ë¡œ DMF ê²€ìƒ‰
    
    Args:
        ingredient: ê²€ìƒ‰ í‚¤ì›Œë“œ (ë¶€ë¶„ ë§¤ì¹­)
        linked_filter: 'linked' = ì—°ê³„ì‹¬ì‚¬ ìˆëŠ” ê²ƒë§Œ, 'unlinked' = ì—†ëŠ” ê²ƒë§Œ, None = ì „ì²´
    """
    try:
        active = _get_cached_data()

        mask = active['ì„±ë¶„ëª…'].astype(str).str.contains(ingredient, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return {"ê²€ìƒ‰ì–´": ingredient, "ë©”ì‹œì§€": f"'{ingredient}' ê´€ë ¨ DMF ë“±ë¡ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        found_copy = found.copy()
        found_copy['base_dmf'] = found_copy['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
            lambda x: x.split('(')[0] if '(' in x else x
        )

        # ì„±ë¶„ëª…ë³„ë¡œ ê·¸ë£¹í•‘ (ë™ì¼ í‚¤ì›Œë“œë¼ë„ ë‹¤ë¥¸ ì„±ë¶„ì€ ë¶„ë¦¬)
        ingredient_groups = []
        total_mfr_count = 0
        total_linked_count = 0

        for ing_name, ing_group in found_copy.groupby('ì„±ë¶„ëª…'):
            # ì´ ì„±ë¶„ì˜ ì œì¡°ì›ë³„ ë¶„ì„
            manufacturers = []
            for base, group in ing_group.groupby('base_dmf'):
                first_row = group[~group['is_í—ˆì—¬']]
                if len(first_row) == 0:
                    first_row = group.iloc[:1]
                first_row = first_row.iloc[0]

                heo_count = int(group['is_í—ˆì—¬'].sum())
                is_linked = bool(first_row['has_ì—°ê³„ì‹¬ì‚¬'])
                status = 'ì •ìƒ' if (group['ì·¨ì†Œ/ì·¨í•˜êµ¬ë¶„'] == 'ì •ìƒ').any() else 'ì·¨ì†Œ/ì·¨í•˜'

                mfr_data = {
                    "base_dmf": base,
                    "ì œì¡°ì†Œ": str(first_row.get('ì œì¡°ì†Œëª…', '')),
                    "êµ­ê°€": str(first_row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/'),
                    "ì‹ ì²­ì¸": str(first_row.get('ì‹ ì²­ì¸', '')),
                    "ë“±ë¡ì¼": first_row['ìµœì´ˆë“±ë¡ì¼ì'].strftime('%Y-%m-%d') if pd.notna(first_row['ìµœì´ˆë“±ë¡ì¼ì']) else '',
                    "í—ˆì—¬_ìˆ˜": heo_count,
                    "ì—°ê³„ì‹¬ì‚¬": is_linked,
                    "ìƒíƒœ": status
                }

                # í•„í„° ì ìš©
                if linked_filter == 'linked' and not is_linked:
                    continue
                if linked_filter == 'unlinked' and is_linked:
                    continue

                manufacturers.append(mfr_data)

            if not manufacturers:
                continue

            linked_count = sum(1 for m in manufacturers if m['ì—°ê³„ì‹¬ì‚¬'])
            total_mfr_count += len(manufacturers)
            total_linked_count += linked_count

            # êµ­ê°€ë³„ ë¶„í¬
            country_dist = Counter()
            for m in manufacturers:
                main_country = m['êµ­ê°€'].split('/')[0]
                country_dist[main_country] += 1

            ingredient_groups.append({
                "ì„±ë¶„ëª…": str(ing_name),
                "ì œì¡°ì›ìˆ˜": len(manufacturers),
                "ì—°ê³„ì‹¬ì‚¬_ìˆ˜": linked_count,
                "êµ­ê°€ë³„_ë¶„í¬": [{"êµ­ê°€": k, "ìˆ˜": v} for k, v in country_dist.most_common()],
                "ì œì¡°ì›_ëª©ë¡": manufacturers
            })

        if not ingredient_groups:
            filter_msg = "ì—°ê³„ì‹¬ì‚¬ ë“±ë¡ëœ" if linked_filter == 'linked' else "ì—°ê³„ì‹¬ì‚¬ ë¯¸ë“±ë¡"
            return {"ê²€ìƒ‰ì–´": ingredient, "ë©”ì‹œì§€": f"'{ingredient}' ì¤‘ {filter_msg} ì œì¡°ì›ì´ ì—†ìŠµë‹ˆë‹¤.", "ì´ê±´ìˆ˜": 0}

        return {
            "ê²€ìƒ‰ì–´": ingredient,
            "í•„í„°": linked_filter,
            "ì„±ë¶„_ì¢…ë¥˜ìˆ˜": len(ingredient_groups),
            "ì´_ì œì¡°ì›ìˆ˜": total_mfr_count,
            "ì´_ì—°ê³„ì‹¬ì‚¬ìˆ˜": total_linked_count,
            "ì„±ë¶„ë³„_í˜„í™©": ingredient_groups
        }
    except Exception as e:
        logger.error(f"ì„±ë¶„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def search_country(country: str) -> dict:
    """êµ­ê°€ë³„ DMF ê²€ìƒ‰"""
    try:
        active = _get_cached_data()

        mask = active['ì œì¡°êµ­ê°€'].astype(str).str.contains(country, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return {"ê²€ìƒ‰_êµ­ê°€": country, "ë©”ì‹œì§€": f"'{country}' ê´€ë ¨ DMF ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        three_months_ago = datetime.today() - timedelta(days=90)
        recent = found[found['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(three_months_ago)]

        top_ingredients = found['ì„±ë¶„ëª…'].value_counts().head(10)
        ingredient_list = [
            {"ì„±ë¶„ëª…": name, "ê±´ìˆ˜": int(cnt)}
            for name, cnt in top_ingredients.items()
        ]

        top_mfrs = found['ì œì¡°ì†Œëª…'].value_counts().head(10)
        mfr_list = [
            {"ì œì¡°ì†Œ": name, "ê±´ìˆ˜": int(cnt)}
            for name, cnt in top_mfrs.items()
        ]

        return {
            "ê²€ìƒ‰_êµ­ê°€": country,
            "ì „ì²´_ë“±ë¡ê±´ìˆ˜": len(found),
            "ìµœê·¼3ê°œì›”_ì‹ ê·œ": len(recent),
            "ì£¼ìš”_ì„±ë¶„_TOP10": ingredient_list,
            "ì£¼ìš”_ì œì¡°ì†Œ_TOP10": mfr_list
        }
    except Exception as e:
        logger.error(f"êµ­ê°€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def search_applicant(applicant: str, month: int = None) -> dict:
    """ì‹ ì²­ì¸ë³„ DMF ê²€ìƒ‰"""
    try:
        active = _get_cached_data()

        mask = active['ì‹ ì²­ì¸'].astype(str).str.contains(applicant, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return {"ê²€ìƒ‰_ì‹ ì²­ì¸": applicant, "ë©”ì‹œì§€": f"'{applicant}' ê´€ë ¨ DMF ë“±ë¡ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        # ì›” í•„í„°
        if month:
            year = datetime.today().year
            found_month = found[
                (found['ìµœì´ˆë“±ë¡ì¼ì'].dt.month == month) &
                (found['ìµœì´ˆë“±ë¡ì¼ì'].dt.year == year)
            ]
            month_label = f"{year}ë…„ {month}ì›”"
        else:
            found_month = found
            month_label = "ì „ì²´"

        # ì„±ë¶„ë³„ í˜„í™©
        ingredient_list = []
        for name, group in found_month.groupby('ì„±ë¶„ëª…'):
            group_copy = group.copy()
            group_copy['base_dmf'] = group_copy['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
                lambda x: x.split('(')[0] if '(' in x else x
            )
            mfr_count = group_copy['base_dmf'].nunique()

            # ì œì¡°ì†Œ ëª©ë¡
            mfrs = []
            for base, bg in group_copy.groupby('base_dmf'):
                first = bg[~bg['is_í—ˆì—¬']]
                if len(first) == 0:
                    first = bg.iloc[:1]
                first = first.iloc[0]
                mfrs.append({
                    "ì œì¡°ì†Œ": str(first.get('ì œì¡°ì†Œëª…', '')),
                    "êµ­ê°€": str(first.get('ì œì¡°êµ­ê°€', '')).replace('@', '/'),
                    "ë“±ë¡ì¼": first['ìµœì´ˆë“±ë¡ì¼ì'].strftime('%Y-%m-%d') if pd.notna(first['ìµœì´ˆë“±ë¡ì¼ì']) else ''
                })

            ingredient_list.append({
                "ì„±ë¶„ëª…": str(name),
                "ë“±ë¡ê±´ìˆ˜": len(group),
                "ì œì¡°ì›ìˆ˜": mfr_count,
                "ì œì¡°ì›": mfrs
            })

        # ì œì¡°êµ­ê°€ ë¶„í¬
        country_dist = Counter()
        for _, row in found_month.iterrows():
            main_country = str(row['ì œì¡°êµ­ê°€']).split('@')[0]
            country_dist[main_country] += 1
        country_list = [{"êµ­ê°€": k, "ê±´ìˆ˜": v} for k, v in country_dist.most_common()]

        return {
            "ê²€ìƒ‰_ì‹ ì²­ì¸": applicant,
            "ê¸°ê°„": month_label,
            "ì´_ë“±ë¡ê±´ìˆ˜": len(found_month),
            "ì·¨ê¸‰_ì„±ë¶„ìˆ˜": len(ingredient_list),
            "êµ­ê°€ë³„_ë¶„í¬": country_list,
            "ì„±ë¶„ë³„_í˜„í™©": sorted(ingredient_list, key=lambda x: x['ë“±ë¡ê±´ìˆ˜'], reverse=True)
        }
    except Exception as e:
        logger.error(f"ì‹ ì²­ì¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def search_manufacturer(keyword: str) -> dict:
    """ì œì¡°ì†Œëª…ìœ¼ë¡œ DMF ê²€ìƒ‰"""
    try:
        active = _get_cached_data()

        mask = active['ì œì¡°ì†Œëª…'].astype(str).str.contains(keyword, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return {"ê²€ìƒ‰_ì œì¡°ì†Œ": keyword, "ë©”ì‹œì§€": f"'{keyword}' ê´€ë ¨ ì œì¡°ì†Œ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        found_copy = found.copy()
        found_copy['base_dmf'] = found_copy['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
            lambda x: x.split('(')[0] if '(' in x else x
        )

        # ì„±ë¶„ë³„ í˜„í™©
        ingredient_list = []
        for name, group in found_copy.groupby('ì„±ë¶„ëª…'):
            mfr_count = group['base_dmf'].nunique()
            linked_count = group[group['has_ì—°ê³„ì‹¬ì‚¬']]['base_dmf'].nunique()
            applicants = group['ì‹ ì²­ì¸'].unique().tolist()

            ingredient_list.append({
                "ì„±ë¶„ëª…": str(name),
                "ì œì¡°ì›ìˆ˜": mfr_count,
                "ì—°ê³„ì‹¬ì‚¬_ìˆ˜": linked_count,
                "ì‹ ì²­ì¸": [a for a in applicants if a][:3]
            })

        # êµ­ê°€ ì •ë³´
        country_dist = Counter()
        for _, row in found_copy.drop_duplicates('base_dmf').iterrows():
            main_country = str(row['ì œì¡°êµ­ê°€']).split('@')[0]
            country_dist[main_country] += 1

        return {
            "ê²€ìƒ‰_ì œì¡°ì†Œ": keyword,
            "ì´_ë“±ë¡ê±´ìˆ˜": len(found),
            "ì·¨ê¸‰_ì„±ë¶„ìˆ˜": len(ingredient_list),
            "êµ­ê°€ë³„_ë¶„í¬": [{"êµ­ê°€": k, "ê±´ìˆ˜": v} for k, v in country_dist.most_common()],
            "ì„±ë¶„ë³„_í˜„í™©": sorted(ingredient_list, key=lambda x: x['ì œì¡°ì›ìˆ˜'], reverse=True)
        }
    except Exception as e:
        logger.error(f"ì œì¡°ì†Œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def search_universal(keyword: str, month: int = None) -> tuple:
    """
    í†µí•© ê²€ìƒ‰: ì„±ë¶„ëª… â†’ ì‹ ì²­ì¸ â†’ ì œì¡°ì†Œëª… ìˆœì„œë¡œ ê²€ìƒ‰
    Returns: (search_type, data) íŠœí”Œ
        search_type: 'ingredient' | 'applicant' | 'manufacturer' | 'none'
    """
    active = _get_cached_data()

    # 1ìˆœìœ„: ì„±ë¶„ëª…
    if active['ì„±ë¶„ëª…'].astype(str).str.contains(keyword, case=False, na=False).any():
        return ('ingredient', None)  # ê¸°ì¡´ search_ingredient ì‚¬ìš©

    # 2ìˆœìœ„: ì‹ ì²­ì¸
    if active['ì‹ ì²­ì¸'].astype(str).str.contains(keyword, case=False, na=False).any():
        return ('applicant', search_applicant(keyword, month))

    # 3ìˆœìœ„: ì œì¡°ì†Œëª…
    if active['ì œì¡°ì†Œëª…'].astype(str).str.contains(keyword, case=False, na=False).any():
        return ('manufacturer', search_manufacturer(keyword))

    return ('none', None)


def generate_chat_summary() -> str:
    """ì¹´ì¹´ì˜¤í†¡ ê³µìœ ìš© ê°„ê²°í•œ ìš”ì•½ ë©”ì‹œì§€"""
    try:
        active = _get_cached_data()

        today = datetime.today()
        days_since_monday = today.weekday()
        this_monday = today - timedelta(days=days_since_monday)
        last_monday = this_monday - timedelta(days=7)
        last_friday = last_monday + timedelta(days=4)

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(last_monday)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(last_friday))
        week_df = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        week_label = f"{last_monday.strftime('%m/%d')}~{last_friday.strftime('%m/%d')}"

        lines = []
        lines.append(f"ğŸ“‹ DMF ì£¼ê°„ í˜„í™© ({week_label})")
        lines.append(f"{'='*28}")

        if len(week_df) == 0:
            lines.append("í•´ë‹¹ ì£¼ê°„ ì‹ ê·œ DMF ë“±ë¡ ì—†ìŒ")
        else:
            initial = int((~week_df['is_í—ˆì—¬']).sum())
            change = int(week_df['is_í—ˆì—¬'].sum())
            linked = int(week_df['has_ì—°ê³„ì‹¬ì‚¬'].sum())

            lines.append(f"ì´ {len(week_df)}ê±´ (ìµœì´ˆ {initial} / í—ˆì—¬ {change})")
            lines.append(f"ì—°ê³„ì‹¬ì‚¬ {linked}ê±´")
            lines.append("")

            for _, row in week_df.iterrows():
                reg_type = "ğŸ”µìµœì´ˆ" if not row['is_í—ˆì—¬'] else "ğŸŸ¡í—ˆì—¬"
                linked_mark = "âœ…" if row['has_ì—°ê³„ì‹¬ì‚¬'] else ""
                country = str(row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/').strip()
                ingredient = str(row.get('ì„±ë¶„ëª…', ''))
                applicant = str(row.get('ì‹ ì²­ì¸', ''))

                lines.append(f"{reg_type} {ingredient}")
                lines.append(f"  {applicant} | {country} {linked_mark}")

            lines.append("")
            lines.append("ì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ DMF ì‹¬ì‚¬ê²°ê³¼")

        return "\n".join(lines)
    except Exception as e:
        logger.error(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        raise


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# [1] MCP ì„œë²„ ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if MCP_AVAILABLE:
    mcp = FastMCP(
        "dmf-intelligence",
        instructions="""DMF(Drug Master File) ë“±ë¡ í˜„í™©ì„ ì¡°íšŒÂ·ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
        ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼(nedrug.mfds.go.kr)ì˜ ê³µê°œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        ì‹ ê·œ DMF ë“±ë¡, êµ­ê°€ë³„/ì„±ë¶„ë³„ ë¶„ì„, ê²½ìŸ ë™í–¥ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    )

    @mcp.tool()
    def get_weekly_dmf(weeks_ago: int = 1) -> str:
        """ìµœê·¼ ì£¼ê°„ DMF ë“±ë¡ í˜„í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            return json.dumps(analyze_weekly_dmf(weeks_ago), ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    @mcp.tool()
    def get_monthly_dmf_summary(months_ago: int = 1) -> str:
        """ì›”ê°„ DMF ë“±ë¡ í˜„í™© ìš”ì•½ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            return json.dumps(analyze_monthly_dmf(months_ago), ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    @mcp.tool()
    def search_dmf_by_ingredient(ingredient: str) -> str:
        """íŠ¹ì • ì„±ë¶„ëª…ìœ¼ë¡œ DMF ë“±ë¡ í˜„í™©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            return json.dumps(search_ingredient(ingredient), ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    @mcp.tool()
    def search_dmf_by_country(country: str) -> str:
        """íŠ¹ì • êµ­ê°€ì˜ DMF ë“±ë¡ í˜„í™©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            return json.dumps(search_country(country), ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    @mcp.tool()
    def get_dmf_chat_summary() -> str:
        """ì¹´ì¹´ì˜¤í†¡ ê³µìœ ìš© ê°„ê²°í•œ DMF ìš”ì•½ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            return generate_chat_summary()
        except Exception as e:
            return f"âŒ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# [2] ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë” Skill ì›¹í›… API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@asynccontextmanager
async def lifespan(app):
    """ì„œë²„ ì‹œì‘ ì‹œ ìºì‹œ í”„ë¦¬ë¡œë“œ"""
    thread = threading.Thread(target=_preload_cache, daemon=True)
    thread.start()
    logger.info("ğŸš€ ë°±ê·¸ë¼ìš´ë“œ ìºì‹œ í”„ë¦¬ë¡œë“œ ì‹œì‘")
    yield

app = FastAPI(title="DMF Intelligence Server", version="2.0", lifespan=lifespan)


def kakao_simple_text(text: str) -> dict:
    """ì¹´ì¹´ì˜¤ ì˜¤í”ˆë¹Œë” simpleText ì‘ë‹µ ìƒì„±"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [
                {"simpleText": {"text": text}}
            ]
        }
    }


def kakao_text_with_buttons(text: str, buttons: list) -> dict:
    """ì¹´ì¹´ì˜¤ ì˜¤í”ˆë¹Œë” í…ìŠ¤íŠ¸ + ë²„íŠ¼ ì‘ë‹µ ìƒì„±"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [
                {
                    "basicCard": {
                        "description": text,
                        "buttons": buttons
                    }
                }
            ]
        }
    }


def kakao_quick_replies(text: str, replies: list) -> dict:
    """ì¹´ì¹´ì˜¤ ì˜¤í”ˆë¹Œë” í…ìŠ¤íŠ¸ + ë°”ë¡œê°€ê¸° ì‘ë‹µ ìƒì„±"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [
                {"simpleText": {"text": text}}
            ],
            "quickReplies": replies
        }
    }


def format_weekly_for_kakao(data: dict) -> str:
    """ì£¼ê°„ ë¶„ì„ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì´ê±´ìˆ˜", 0) == 0:
        return f"ğŸ“‹ DMF ì£¼ê°„ í˜„í™© ({data['ê¸°ê°„']})\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸ“‹ DMF ì£¼ê°„ í˜„í™© ({data['ê¸°ê°„']})",
        f"{'â”€'*24}",
        f"ì´ {data['ì´ê±´ìˆ˜']}ê±´ (ìµœì´ˆ {data['ìµœì´ˆë“±ë¡']} / í—ˆì—¬ {data['í—ˆì—¬_ë³€ê²½']})",
        f"ì—°ê³„ì‹¬ì‚¬ {data['ì—°ê³„ì‹¬ì‚¬_ìˆìŒ']}ê±´",
        ""
    ]

    for item in data.get("ìƒì„¸ë‚´ì—­", [])[:15]:  # ì¹´ì¹´ì˜¤í†¡ ê¸€ììˆ˜ ì œí•œ ê³ ë ¤
        reg_icon = "ğŸ”µ" if item['ë“±ë¡ìœ í˜•'] == 'ìµœì´ˆ' else "ğŸŸ¡"
        linked = " âœ…" if item['ì—°ê³„ì‹¬ì‚¬'] == 'O' else ""
        lines.append(f"{reg_icon} {item['ì„±ë¶„ëª…']}")
        lines.append(f"  {item['ì‹ ì²­ì¸']} | {item['êµ­ê°€']}{linked}")

    if len(data.get("ìƒì„¸ë‚´ì—­", [])) > 15:
        lines.append(f"\n... ì™¸ {len(data['ìƒì„¸ë‚´ì—­']) - 15}ê±´")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_monthly_for_kakao(data: dict) -> str:
    """ì›”ê°„ ë¶„ì„ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    lines = [
        f"ğŸ“Š DMF ì›”ê°„ ë¦¬í¬íŠ¸ ({data['ê¸°ê°„']})",
        f"{'â”€'*24}",
        f"ì´ {data['ì´ê±´ìˆ˜']}ê±´ (ì „ì›” {data['ì „ì›”_ê±´ìˆ˜']}ê±´, {data['ì „ì›”ëŒ€ë¹„_ë³€ë™']})",
        f"  ìµœì´ˆë“±ë¡ {data['ìµœì´ˆë“±ë¡']}ê±´ / í—ˆì—¬ {data['í—ˆì—¬_ë³€ê²½']}ê±´",
        ""
    ]

    if data.get("êµ­ê°€ë³„_ë¶„í¬"):
        lines.append("ğŸŒ êµ­ê°€ë³„ ë¶„í¬:")
        for item in data["êµ­ê°€ë³„_ë¶„í¬"][:5]:
            lines.append(f"  {item['êµ­ê°€']}: {item['ê±´ìˆ˜']}ê±´ ({item['ë¹„ìœ¨']})")

    if data.get("ì£¼ìš”_ì‹ ì²­ì¸_TOP5"):
        lines.append("\nğŸ‘¤ ì£¼ìš” ì‹ ì²­ì¸:")
        for item in data["ì£¼ìš”_ì‹ ì²­ì¸_TOP5"]:
            lines.append(f"  {item['ì‹ ì²­ì¸']}: {item['ê±´ìˆ˜']}ê±´")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_ingredient_for_kakao(data: dict) -> str:
    """ì„±ë¶„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§· (ì„±ë¶„ëª…ë³„ ê·¸ë£¹í•‘)"""
    if data.get("ì´ê±´ìˆ˜", 0) == 0 and data.get("ì´_ì œì¡°ì›ìˆ˜", 0) == 0:
        return f"ğŸ” '{data['ê²€ìƒ‰ì–´']}' ê²€ìƒ‰ ê²°ê³¼\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    linked_filter = data.get("í•„í„°")
    filter_label = ""
    if linked_filter == 'linked':
        filter_label = " [ì—°ê³„ì‹¬ì‚¬ âœ…]"
    elif linked_filter == 'unlinked':
        filter_label = " [ë¯¸ì—°ê³„]"

    lines = [
        f"ğŸ” '{data['ê²€ìƒ‰ì–´']}' DMF í˜„í™©{filter_label}",
        f"{'â”€'*24}",
        f"ğŸ“‹ ì„±ë¶„ {data['ì„±ë¶„_ì¢…ë¥˜ìˆ˜']}ì¢… | ì œì¡°ì› {data['ì´_ì œì¡°ì›ìˆ˜']}ê°œì‚¬ | ì—°ê³„ {data['ì´_ì—°ê³„ì‹¬ì‚¬ìˆ˜']}ê°œ",
    ]

    # ì„±ë¶„ë³„ ìƒì„¸
    for ig in data.get("ì„±ë¶„ë³„_í˜„í™©", []):
        lines.append(f"\n{'â”'*24}")
        lines.append(f"ğŸ’Š {ig['ì„±ë¶„ëª…']}")

        # êµ­ê°€ë³„ ë¶„í¬
        dist = ig.get("êµ­ê°€ë³„_ë¶„í¬", [])
        if dist:
            dist_str = " | ".join([f"{c['êµ­ê°€']} {c['ìˆ˜']}" for c in dist[:4]])
            lines.append(f"   ğŸŒ {dist_str}")

        lines.append(f"   ì œì¡°ì› {ig['ì œì¡°ì›ìˆ˜']}ê°œ (ì—°ê³„ {ig['ì—°ê³„ì‹¬ì‚¬_ìˆ˜']}ê°œ)")

        # ì œì¡°ì› ëª©ë¡ (ì „ì²´ í‘œì‹œ, 1ì¤„ë¡œ ì••ì¶•)
        for m in ig.get("ì œì¡°ì›_ëª©ë¡", []):
            linked_mark = "âœ…" if m['ì—°ê³„ì‹¬ì‚¬'] else "â¬œ"
            status_mark = "âŒ" if m['ìƒíƒœ'] != 'ì •ìƒ' else ""
            heo = f"+{m['í—ˆì—¬_ìˆ˜']}í—ˆì—¬" if m['í—ˆì—¬_ìˆ˜'] > 0 else ""
            country = m['êµ­ê°€'].split('/')[0]  # ì²« ë²ˆì§¸ êµ­ê°€ë§Œ
            lines.append(f"  {linked_mark} {m['ì œì¡°ì†Œ'][:20]} ({country})")
            lines.append(f"     {m['ì‹ ì²­ì¸'][:12]} {heo}{status_mark}")

    lines.append(f"\n{'â”€'*24}")
    lines.append("ì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_country_for_kakao(data: dict) -> str:
    """êµ­ê°€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì „ì²´_ë“±ë¡ê±´ìˆ˜", 0) == 0:
        return f"ğŸŒ '{data['ê²€ìƒ‰_êµ­ê°€']}' ê²€ìƒ‰ ê²°ê³¼\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸŒ {data['ê²€ìƒ‰_êµ­ê°€']} DMF í˜„í™©",
        f"{'â”€'*24}",
        f"ì „ì²´ {data['ì „ì²´_ë“±ë¡ê±´ìˆ˜']}ê±´ (ìµœê·¼3ê°œì›” {data['ìµœê·¼3ê°œì›”_ì‹ ê·œ']}ê±´)",
        ""
    ]

    if data.get("ì£¼ìš”_ì„±ë¶„_TOP10"):
        lines.append("ğŸ’Š ì£¼ìš” ì„±ë¶„:")
        for item in data["ì£¼ìš”_ì„±ë¶„_TOP10"][:7]:
            lines.append(f"  {item['ì„±ë¶„ëª…']}: {item['ê±´ìˆ˜']}ê±´")

    if data.get("ì£¼ìš”_ì œì¡°ì†Œ_TOP10"):
        lines.append("\nğŸ­ ì£¼ìš” ì œì¡°ì†Œ:")
        for item in data["ì£¼ìš”_ì œì¡°ì†Œ_TOP10"][:5]:
            lines.append(f"  {item['ì œì¡°ì†Œ'][:25]}: {item['ê±´ìˆ˜']}ê±´")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_applicant_for_kakao(data: dict) -> str:
    """ì‹ ì²­ì¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì´_ë“±ë¡ê±´ìˆ˜", 0) == 0:
        return f"ğŸ‘¤ '{data['ê²€ìƒ‰_ì‹ ì²­ì¸']}' ê²€ìƒ‰ ê²°ê³¼\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸ‘¤ '{data['ê²€ìƒ‰_ì‹ ì²­ì¸']}' DMF í˜„í™©",
        f"   ({data['ê¸°ê°„']})",
        f"{'â”€'*24}",
        f"ğŸ“‹ ì´ {data['ì´_ë“±ë¡ê±´ìˆ˜']}ê±´ | ì·¨ê¸‰ ì„±ë¶„ {data['ì·¨ê¸‰_ì„±ë¶„ìˆ˜']}ì¢…",
    ]

    # êµ­ê°€ë³„ ë¶„í¬
    country_dist = data.get("êµ­ê°€ë³„_ë¶„í¬", [])
    if country_dist:
        dist_str = " | ".join([f"{c['êµ­ê°€']} {c['ê±´ìˆ˜']}" for c in country_dist[:4]])
        lines.append(f"ğŸŒ {dist_str}")

    lines.append(f"{'â”€'*24}")

    # ì„±ë¶„ë³„ í˜„í™©
    ingredients = data.get("ì„±ë¶„ë³„_í˜„í™©", [])
    if ingredients:
        for item in ingredients[:8]:
            lines.append(f"\nğŸ’Š {item['ì„±ë¶„ëª…'][:20]}")
            lines.append(f"   ì œì¡°ì› {item['ì œì¡°ì›ìˆ˜']}ê°œì‚¬")
            for mfr in item.get('ì œì¡°ì›', [])[:3]:
                lines.append(f"   â–ª {mfr['ì œì¡°ì†Œ'][:22]} ({mfr['êµ­ê°€']})")

    if len(ingredients) > 8:
        lines.append(f"\n... ì™¸ {len(ingredients) - 8}ê°œ ì„±ë¶„")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_manufacturer_for_kakao(data: dict) -> str:
    """ì œì¡°ì†Œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì´ê±´ìˆ˜", 0) == 0:
        return f"ğŸ­ '{data['ê²€ìƒ‰_ì œì¡°ì†Œ']}' ê²€ìƒ‰ ê²°ê³¼\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸ­ '{data['ê²€ìƒ‰_ì œì¡°ì†Œ']}' ì œì¡°ì†Œ í˜„í™©",
        f"{'â”€'*24}",
        f"ğŸ“‹ ì´ {data['ì´_ë“±ë¡ê±´ìˆ˜']}ê±´ | ì·¨ê¸‰ ì„±ë¶„ {data['ì·¨ê¸‰_ì„±ë¶„ìˆ˜']}ì¢…",
    ]

    country_dist = data.get("êµ­ê°€ë³„_ë¶„í¬", [])
    if country_dist:
        dist_str = " | ".join([f"{c['êµ­ê°€']} {c['ê±´ìˆ˜']}" for c in country_dist[:4]])
        lines.append(f"ğŸŒ {dist_str}")

    lines.append(f"{'â”€'*24}")

    ingredients = data.get("ì„±ë¶„ë³„_í˜„í™©", [])
    if ingredients:
        for item in ingredients[:12]:
            linked_mark = f"âœ…{item['ì—°ê³„ì‹¬ì‚¬_ìˆ˜']}" if item['ì—°ê³„ì‹¬ì‚¬_ìˆ˜'] > 0 else "â¬œ0"
            apps = ", ".join(item.get('ì‹ ì²­ì¸', [])[:2])
            lines.append(f"ğŸ’Š {item['ì„±ë¶„ëª…'][:20]}")
            lines.append(f"   ì œì¡°ì› {item['ì œì¡°ì›ìˆ˜']}ê°œ | ì—°ê³„ {linked_mark} | {apps[:15]}")

    if len(ingredients) > 12:
        lines.append(f"\n... ì™¸ {len(ingredients) - 12}ê°œ ì„±ë¶„")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def parse_user_intent(utterance: str) -> tuple:
    """
    ì‚¬ìš©ì ë°œí™”ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë„ì™€ íŒŒë¼ë¯¸í„° ì¶”ì¶œ

    Returns:
        (intent, params) íŠœí”Œ
        intent: 'weekly' | 'monthly' | 'ingredient' | 'country' | 'applicant' | 'summary' | 'help'
    """
    text = utterance.strip().lower()

    # ì£¼ê°„
    if any(kw in text for kw in ['ì£¼ê°„', 'ì´ë²ˆì£¼', 'ì´ë²ˆ ì£¼', 'ê¸ˆì£¼', 'ì§€ë‚œì£¼', 'ì§€ë‚œ ì£¼', 'ì£¼ë³„']):
        return ('weekly', {})

    # ì›”ê°„
    if any(kw in text for kw in ['ì›”ê°„', 'ì´ë²ˆë‹¬', 'ì´ë²ˆ ë‹¬', 'ì „ì›”', 'ì§€ë‚œë‹¬', 'ì§€ë‚œ ë‹¬', 'ì›”ë³„']):
        return ('monthly', {})

    # ìš”ì•½ / ì±„íŒ… ê³µìœ 
    if any(kw in text for kw in ['ìš”ì•½', 'ê³µìœ ', 'ì •ë¦¬', 'ì¹´í†¡', 'ì±—']):
        return ('summary', {})

    # ì‹ ì²­ì¸ ê²€ìƒ‰ (íŒ¨í„´: "ì‹ ì²­ì¸ íŒŒë§ˆí”¼ì•„", "1ì›”ì— ì‹ ì²­ì¸ íŒŒë§ˆí”¼ì•„ í˜„í™©")
    # ì›” ì¶”ì¶œ
    month_match = re.search(r'(\d{1,2})ì›”', text)
    month = int(month_match.group(1)) if month_match else None

    # "ì‹ ì²­ì¸ XXX" íŒ¨í„´
    applicant_match = re.search(r'(?:ì‹ ì²­ì¸|ìˆ˜ì…ì‚¬|ìˆ˜ì…ì—…ì²´|ê±°ë˜ì²˜)\s*[:]?\s*(.+?)(?:\s*(?:í˜„í™©|ê²€ìƒ‰|ì¡°íšŒ|dmf|ë“±ë¡|ëª‡ê°œ|ê°¯ìˆ˜).*$|\s*\??\s*$)', text)
    if applicant_match:
        name = applicant_match.group(1).strip()
        if name:
            return ('applicant', {'applicant': name, 'month': month})

    # "XXX ì‹ ì²­ì¸" íŒ¨í„´  (e.g., "íŒŒë§ˆí”¼ì•„ ì‹ ì²­")
    applicant_match2 = re.search(r'^(.+?)\s*(?:ì‹ ì²­ì¸|ìˆ˜ì…ì‚¬|ìˆ˜ì…ì—…ì²´)\s*(?:í˜„í™©|ê²€ìƒ‰|ì¡°íšŒ|dmf|$)', text)
    if applicant_match2:
        name = applicant_match2.group(1).strip()
        # ì›” ì •ë³´ ì œê±°
        name = re.sub(r'\d{1,2}ì›”\s*(?:ì—|ì˜)?\s*', '', name).strip()
        if name:
            return ('applicant', {'applicant': name, 'month': month})

    # êµ­ê°€ ê²€ìƒ‰ (íŒ¨í„´: "ì¸ë„ DMF", "ì¤‘êµ­ í˜„í™©" ë“±)
    country_keywords = ['ì¸ë„', 'ì¤‘êµ­', 'ì¼ë³¸', 'ë¯¸êµ­', 'ë…ì¼', 'ì´íƒˆë¦¬ì•„', 'ìŠ¤í˜ì¸',
                        'í”„ë‘ìŠ¤', 'ì˜êµ­', 'ìºë‚˜ë‹¤', 'ë¸Œë¼ì§ˆ', 'ëŒ€ë§Œ', 'í•œêµ­', 'ì´ìŠ¤ë¼ì—˜',
                        'india', 'china', 'japan', 'usa', 'germany', 'italy', 'spain']
    for kw in country_keywords:
        if kw in text:
            return ('country', {'country': kw})

    # êµ­ê°€ íŒ¨í„´: "~ë‚˜ë¼ DMF", "~êµ­ê°€ í˜„í™©"
    country_match = re.search(r'(\S+)\s*(ë‚˜ë¼|êµ­ê°€)\s*(dmf|í˜„í™©|ì œì¡°)', text)
    if country_match:
        return ('country', {'country': country_match.group(1)})

    # ë„ì›€ë§ / ë©”ë‰´
    if any(kw in text for kw in ['ë„ì›€', 'ì‚¬ìš©ë²•', 'ì•ˆë‚´', 'ë©”ë‰´', 'ë­˜ í•  ìˆ˜', 'ê¸°ëŠ¥', 'ëª…ë ¹', 'ë­ í• ', 'ë­˜ ë¬¼', 'ì–´ë–»ê²Œ']):
        return ('help', {})

    # ì„±ë¶„ëª…/í†µí•© ê²€ìƒ‰ (ì—°ê³„ì‹¬ì‚¬ í•„í„° + ì›” í•„í„° í¬í•¨)
    # ì—°ê³„ì‹¬ì‚¬ í•„í„° ê°ì§€
    linked_filter = None
    if any(kw in text for kw in ['ì—°ê³„ ì•ˆ', 'ë¯¸ì—°ê³„', 'ì—°ê³„ì•ˆ', 'ë¹„ì—°ê³„', 'ì—°ê³„ ì—†']):
        linked_filter = 'unlinked'
    elif any(kw in text for kw in ['ì—°ê³„ì‹¬ì‚¬', 'ì—°ê³„', 'linked']):
        linked_filter = 'linked'

    # ì›” ì¶”ì¶œ (ì—¬ê¸°ì„œë„ ì²´í¬ â€” ì‹ ì²­ì¸ ì¸í…íŠ¸ì—ì„œ ëª» ì¡ì•˜ì„ ê²½ìš°)
    month_match = re.search(r'(\d{1,2})ì›”', text)
    month = int(month_match.group(1)) if month_match else None

    # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ (ë¶ˆí•„ìš” ë‹¨ì–´ ëª¨ë‘ ì œê±°)
    clean_text = re.sub(
        r'\s*(?:ì¤‘|ì—ì„œ|ì˜|ì—)?\s*(?:ì—°ê³„ì‹¬ì‚¬|ë¯¸ì—°ê³„|ë¹„ì—°ê³„|ì—°ê³„|ì œì¡°ì›|ì œì¡°ì‚¬|í˜„í™©|ê²€ìƒ‰|ì¡°íšŒ|dmf|ë“±ë¡|í—ˆì—¬|ëœ|ì•ˆëœ|ìˆëŠ”|ì—†ëŠ”|ëª‡ê°œ|ê°¯ìˆ˜|ìˆ˜|ì•Œë ¤ì¤˜|ë³´ì—¬ì¤˜|ë­ì•¼)\s*',
        ' ', text
    ).strip()
    # ì›” íŒ¨í„´ ì œê±° ("1ì›”ì—", "1ì›”", "2ì›”ì˜" ë“±)
    clean_text = re.sub(r'\d{1,2}ì›”\s*(?:ì—|ì˜|ì€|ëŠ”)?\s*', '', clean_text).strip()
    # ë‚¨ì€ ì¡°ì‚¬/ê¸°í˜¸ ì •ë¦¬
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    clean_text = re.sub(r'[?ï¼Ÿ!]$', '', clean_text).strip()
    clean_text = re.sub(r'(?:ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼)$', '', clean_text).strip()

    if clean_text and clean_text not in ['ì•ˆë…•', 'í•˜ì´', 'hi', 'hello', 'ì‹œì‘'] and len(clean_text) > 1:
        return ('ingredient', {'ingredient': clean_text, 'linked_filter': linked_filter, 'month': month})

    # ë„ˆë¬´ ì§§ê±°ë‚˜ ì¼ë°˜ì ì¸ ì¸ì‚¬ëŠ” helpë¡œ
    if len(text) <= 1 or text in ['ì•ˆë…•', 'í•˜ì´', 'hi', 'hello', 'ì‹œì‘']:
        return ('help', {})

    return ('ingredient', {'ingredient': utterance.strip(), 'linked_filter': linked_filter, 'month': month})


# â”€â”€â”€ ì¹´ì¹´ì˜¤ ì›¹í›… ì—”ë“œí¬ì¸íŠ¸ë“¤ â”€â”€â”€

@app.get("/")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "service": "DMF Intelligence Server",
        "cache": "loaded" if _cache["df"] is not None else "empty",
        "last_updated": str(_cache["last_updated"]) if _cache["last_updated"] else None,
        "endpoints": {
            "kakao_webhook": "/kakao/skill",
            "mcp_sse": "/sse" if MCP_AVAILABLE else "not available"
        }
    }


@app.get("/refresh")
async def refresh_cache():
    """ìºì‹œ ê°•ì œ ê°±ì‹  (Cron Jobìš©) â€” ë§¤ì¼ ì•„ì¹¨ 7ì‹œ í˜¸ì¶œ"""
    try:
        _cache["df"] = None
        _cache["last_updated"] = None
        _get_cached_data()
        return {
            "status": "refreshed",
            "records": len(_cache["df"]),
            "updated_at": str(_cache["last_updated"])
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.post("/kakao/skill")
async def kakao_skill_handler(request: Request):
    """
    ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë” í†µí•© Skill ì—”ë“œí¬ì¸íŠ¸
    
    ì‚¬ìš©ì ë°œí™”ë¥¼ ìë™ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ DMF ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì˜¤í”ˆë¹Œë”ì˜ 'í´ë°± ë¸”ë¡'ì— ì—°ê²°í•˜ë©´, ëª¨ë“  ì…ë ¥ì„ ì—¬ê¸°ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        body = await request.json()
        utterance = body.get("userRequest", {}).get("utterance", "")
        params = body.get("action", {}).get("params", {})

        logger.info(f"ğŸ“¨ ì¹´ì¹´ì˜¤ ìš”ì²­: '{utterance}' | params: {params}")

        # ìºì‹œê°€ ì•„ì§ ì¤€ë¹„ ì•ˆ ëìœ¼ë©´ ì¦‰ì‹œ ì•ˆë‚´
        if _cache["df"] is None and _cache["loading"]:
            return JSONResponse(kakao_simple_text(
                "ğŸ”„ ì„œë²„ê°€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.\n10ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!"
            ))

        intent, extracted = parse_user_intent(utterance)

        if intent == 'weekly':
            data = analyze_weekly_dmf()
            text = format_weekly_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ìš”ì•½", "action": "message", "label": "ğŸ“‹ ì±„íŒ… ê³µìœ ìš©"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ì‚¬ìš©ë²•"}
            ]))

        elif intent == 'monthly':
            data = analyze_monthly_dmf()
            text = format_monthly_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì¸ë„", "action": "message", "label": "ğŸ‡®ğŸ‡³ ì¸ë„ DMF"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ì‚¬ìš©ë²•"}
            ]))

        elif intent == 'summary':
            text = generate_chat_summary()
            return JSONResponse(kakao_simple_text(text))

        elif intent == 'country':
            country = extracted.get('country', params.get('country', ''))
            if not country:
                return JSONResponse(kakao_simple_text("ì–´ëŠ êµ­ê°€ì˜ DMFë¥¼ ê²€ìƒ‰í• ê¹Œìš”?\n\nì˜ˆ: ì¸ë„, ì¤‘êµ­, ì¼ë³¸, ë¯¸êµ­"))
            data = search_country(country)
            text = format_country_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
            ]))

        elif intent == 'applicant':
            applicant = extracted.get('applicant', params.get('applicant', ''))
            month = extracted.get('month')
            if not applicant:
                return JSONResponse(kakao_simple_text("ê²€ìƒ‰í•  ì‹ ì²­ì¸ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆ: ì‹ ì²­ì¸ íŒŒë§ˆí”¼ì•„\nì˜ˆ: 1ì›”ì— ì‹ ì²­ì¸ êµ­ì „ì•½í’ˆ í˜„í™©"))
            data = search_applicant(applicant, month)
            text = format_applicant_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
            ]))

        elif intent == 'ingredient':
            keyword = extracted.get('ingredient', params.get('ingredient', ''))
            linked_filter = extracted.get('linked_filter')
            if not keyword:
                return JSONResponse(kakao_simple_text("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆ: í´ë˜ë¦¬, Synthimed, íŒŒë§ˆí”¼ì•„"))

            # ì—°ê³„ í•„í„°ê°€ ìˆìœ¼ë©´ ì„±ë¶„ëª… ê²€ìƒ‰ ê³ ì •
            if linked_filter:
                data = search_ingredient(keyword, linked_filter)
                text = format_ingredient_for_kakao(data)
                replies = []
                if linked_filter != 'linked':
                    replies.append({"messageText": f"{keyword} ì—°ê³„ì‹¬ì‚¬", "action": "message", "label": "âœ… ì—°ê³„ì‹¬ì‚¬ë§Œ"})
                if linked_filter != 'unlinked':
                    replies.append({"messageText": f"{keyword} ë¯¸ì—°ê³„", "action": "message", "label": "â¬œ ë¯¸ì—°ê³„ë§Œ"})
                replies.append({"messageText": keyword, "action": "message", "label": "ğŸ“‹ ì „ì²´ ë³´ê¸°"})
                replies.append({"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"})
                return JSONResponse(kakao_quick_replies(text, replies[:4]))

            # í†µí•© ê²€ìƒ‰: ì„±ë¶„ëª… â†’ ì‹ ì²­ì¸ â†’ ì œì¡°ì†Œëª…
            month = extracted.get('month')
            search_type, uni_data = search_universal(keyword, month)

            if search_type == 'ingredient':
                data = search_ingredient(keyword)
                text = format_ingredient_for_kakao(data)
                return JSONResponse(kakao_quick_replies(text, [
                    {"messageText": f"{keyword} ì—°ê³„ì‹¬ì‚¬", "action": "message", "label": "âœ… ì—°ê³„ì‹¬ì‚¬ë§Œ"},
                    {"messageText": f"{keyword} ë¯¸ì—°ê³„", "action": "message", "label": "â¬œ ë¯¸ì—°ê³„ë§Œ"},
                    {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                ]))

            elif search_type == 'applicant':
                text = format_applicant_for_kakao(uni_data)
                return JSONResponse(kakao_quick_replies(text, [
                    {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                    {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                    {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                ]))

            elif search_type == 'manufacturer':
                text = format_manufacturer_for_kakao(uni_data)
                return JSONResponse(kakao_quick_replies(text, [
                    {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                    {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                    {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                ]))

            else:
                return JSONResponse(kakao_quick_replies(
                    f"ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼\n\nì„±ë¶„ëª…Â·ì‹ ì²­ì¸Â·ì œì¡°ì†Œì—ì„œ\nì¼ì¹˜í•˜ëŠ” í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.",
                    [
                        {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                        {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                    ]
                ))

        else:  # help
            help_text = (
                "ğŸ’Š DMF Intelligence\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ DMF ë°ì´í„°ë¥¼\n"
                "ì‹¤ì‹œê°„ìœ¼ë¡œ ì¡°íšŒÂ·ë¶„ì„í•©ë‹ˆë‹¤.\n\n"
                "ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”!\n\n"
                "ğŸ’¡ ì…ë ¥ ì˜ˆì‹œ:\n"
                "â€¢ í´ë˜ë¦¬ â†’ ì„±ë¶„ë³„ ì œì¡°ì› í˜„í™©\n"
                "â€¢ í´ë˜ë¦¬ ì—°ê³„ì‹¬ì‚¬ â†’ ì—°ê³„ì‹¬ì‚¬ ì œì¡°ì›ë§Œ\n"
                "â€¢ Synthimed â†’ ì œì¡°ì†Œ ê²€ìƒ‰\n"
                "â€¢ íŒŒë§ˆí”¼ì•„ â†’ ì‹ ì²­ì¸ ê²€ìƒ‰\n"
                "â€¢ ì¸ë„ â†’ êµ­ê°€ë³„ DMF í˜„í™©\n"
                "â€¢ ì‹ ì²­ì¸ íŒŒë§ˆí”¼ì•„ â†’ ì‹ ì²­ì¸ ì§€ì • ê²€ìƒ‰\n"
                "â€¢ 1ì›”ì— ì‹ ì²­ì¸ êµ­ì „ì•½í’ˆ â†’ ì›”ë³„ ì‹ ì²­ì¸"
            )
            return JSONResponse(kakao_quick_replies(help_text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ìš”ì•½", "action": "message", "label": "ğŸ“ ì±„íŒ… ê³µìœ ìš©"},
                {"messageText": "ì¸ë„", "action": "message", "label": "ğŸ‡®ğŸ‡³ ì¸ë„ DMF"}
            ]))

    except Exception as e:
        logger.error(f"âŒ ì¹´ì¹´ì˜¤ ìŠ¤í‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return JSONResponse(kakao_simple_text(
            f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\n(ì˜¤ë¥˜: {str(e)[:100]})"
        ))


# ê°œë³„ ìŠ¤í‚¬ ì—”ë“œí¬ì¸íŠ¸ (ì˜¤í”ˆë¹Œë”ì—ì„œ ë¸”ë¡ë³„ë¡œ ì—°ê²°í•  ë•Œ ì‚¬ìš©)
@app.post("/kakao/weekly")
async def kakao_weekly(request: Request):
    """ì£¼ê°„ DMF í˜„í™© ì „ìš© ìŠ¤í‚¬"""
    try:
        data = analyze_weekly_dmf()
        text = format_weekly_for_kakao(data)
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:100]}"))


@app.post("/kakao/monthly")
async def kakao_monthly(request: Request):
    """ì›”ê°„ DMF ë¦¬í¬íŠ¸ ì „ìš© ìŠ¤í‚¬"""
    try:
        data = analyze_monthly_dmf()
        text = format_monthly_for_kakao(data)
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:100]}"))


@app.post("/kakao/summary")
async def kakao_summary(request: Request):
    """ì±„íŒ… ê³µìœ ìš© ìš”ì•½ ì „ìš© ìŠ¤í‚¬"""
    try:
        text = generate_chat_summary()
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ìš”ì•½ ì‹¤íŒ¨: {str(e)[:100]}"))


@app.post("/kakao/ingredient")
async def kakao_ingredient(request: Request):
    """ì„±ë¶„ëª… ê²€ìƒ‰ ì „ìš© ìŠ¤í‚¬ (íŒŒë¼ë¯¸í„°: ingredient)"""
    try:
        body = await request.json()
        utterance = body.get("userRequest", {}).get("utterance", "")
        ingredient = body.get("action", {}).get("params", {}).get("ingredient", utterance)

        if not ingredient:
            return JSONResponse(kakao_simple_text("ê²€ìƒ‰í•  ì„±ë¶„ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."))

        data = search_ingredient(ingredient)
        text = format_ingredient_for_kakao(data)
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)[:100]}"))


@app.post("/kakao/country")
async def kakao_country(request: Request):
    """êµ­ê°€ ê²€ìƒ‰ ì „ìš© ìŠ¤í‚¬ (íŒŒë¼ë¯¸í„°: country)"""
    try:
        body = await request.json()
        utterance = body.get("userRequest", {}).get("utterance", "")
        country = body.get("action", {}).get("params", {}).get("country", utterance)

        if not country:
            return JSONResponse(kakao_simple_text("ê²€ìƒ‰í•  êµ­ê°€ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."))

        data = search_country(country)
        text = format_country_for_kakao(data)
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)[:100]}"))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„œë²„ ì‹¤í–‰ (MCP + ì¹´ì¹´ì˜¤ ë™ì‹œ ì§€ì›)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    mode = os.environ.get("SERVER_MODE", "kakao")  # "kakao" | "mcp" | "both"

    if mode == "mcp" and MCP_AVAILABLE:
        # MCP ì „ìš© ëª¨ë“œ (Claude Desktop / PlayMCP)
        print(f"ğŸš€ DMF MCP Server (SSE) ì‹œì‘ â€” Port {port}")
        mcp.run(transport="sse", port=port)

    elif mode == "both" and MCP_AVAILABLE:
        # ë‘ ì„œë²„ ë™ì‹œ ì‹¤í–‰ (ë³„ë„ í¬íŠ¸)
        import threading
        mcp_port = int(os.environ.get("MCP_PORT", 8001))

        def run_mcp():
            print(f"ğŸš€ MCP Server ì‹œì‘ â€” Port {mcp_port}")
            mcp.run(transport="sse", port=mcp_port)

        mcp_thread = threading.Thread(target=run_mcp, daemon=True)
        mcp_thread.start()

        print(f"ğŸš€ ì¹´ì¹´ì˜¤ ì›¹í›… Server ì‹œì‘ â€” Port {port}")
        uvicorn.run(app, host="0.0.0.0", port=port)

    else:
        # ì¹´ì¹´ì˜¤ ì›¹í›… ì „ìš© ëª¨ë“œ (ê¸°ë³¸)
        print(f"ğŸš€ DMF ì¹´ì¹´ì˜¤ ì±—ë´‡ Server ì‹œì‘ â€” Port {port}")
        print(f"   ì›¹í›… URL: https://YOUR-APP.onrender.com/kakao/skill")
        uvicorn.run(app, host="0.0.0.0", port=port)
