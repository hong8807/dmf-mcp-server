"""
DMF Intelligence Server (MCP + ì¹´ì¹´ì˜¤í†¡ ì±„ë„ ì±—ë´‡)
===================================================
ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ DMF ë°ì´í„°ë¥¼ ì¡°íšŒÂ·ë¶„ì„í•˜ëŠ” í†µí•© ì„œë²„

[1] MCP ì„œë²„: Claude Desktop / PlayMCPì—ì„œ ì‚¬ìš©
[2] ì¹´ì¹´ì˜¤ ì›¹í›… API: ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë” Skill ì„œë²„

ë°°í¬: Render.com â†’ í•˜ë‚˜ì˜ ì„œë²„ë¡œ ë‘ ê¸°ëŠ¥ ëª¨ë‘ ì œê³µ
"""

import os
import json
import tempfile
import logging
import re
import threading
from datetime import datetime, timedelta
from collections import Counter
from typing import Optional
from contextlib import asynccontextmanager

import requests
import pandas as pd
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import uvicorn

# MCP (ì¡°ê±´ë¶€ ì„í¬íŠ¸ â€” MCP ì—†ì´ë„ ì¹´ì¹´ì˜¤ ì›¹í›…ë§Œìœ¼ë¡œ ë™ì‘ ê°€ëŠ¥)
try:
    from mcp.server.fastmcp import FastMCP
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë¡œê¹… ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("dmf-server")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë°ì´í„° ìºì‹± (ì¹´ì¹´ì˜¤ 5ì´ˆ íƒ€ì„ì•„ì›ƒ ëŒ€ì‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import threading

_cache = {
    "df": None,           # ìºì‹±ëœ DataFrame
    "last_updated": None, # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°
    "loading": False      # ë¡œë”© ì¤‘ ì—¬ë¶€
}
CACHE_TTL = timedelta(hours=24)  # í•˜ë£¨ 1íšŒ ê°±ì‹ 


def _download_dmf_excel() -> str:
    """ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ì—ì„œ DMF ì—‘ì…€ ë‹¤ìš´ë¡œë“œ â†’ ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    url = "https://nedrug.mfds.go.kr/pbp/CCBAC03/getExcel"
    logger.info("ğŸ“¥ DMF ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    response = requests.get(url, timeout=120)
    response.raise_for_status()

    tmp = tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False)
    tmp.write(response.content)
    tmp.close()
    logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {tmp.name}")
    return tmp.name


def _get_cached_data() -> pd.DataFrame:
    """ìºì‹±ëœ ë°ì´í„° ë°˜í™˜. ì—†ê±°ë‚˜ ë§Œë£Œë˜ë©´ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ."""
    now = datetime.now()

    # ìºì‹œê°€ ìœ íš¨í•˜ë©´ ë°”ë¡œ ë°˜í™˜
    if (_cache["df"] is not None and
        _cache["last_updated"] is not None and
        now - _cache["last_updated"] < CACHE_TTL):
        logger.info("âš¡ ìºì‹œ ë°ì´í„° ì‚¬ìš©")
        return _cache["df"]

    # ìºì‹œ ê°±ì‹ 
    logger.info("ğŸ”„ ìºì‹œ ê°±ì‹  ì¤‘...")
    excel_path = _download_dmf_excel()
    try:
        df = _load_and_prepare(excel_path)
        _cache["df"] = df
        _cache["last_updated"] = now
        logger.info(f"âœ… ìºì‹œ ê°±ì‹  ì™„ë£Œ ({len(df)}ê±´)")
        return df
    finally:
        os.unlink(excel_path)


def _preload_cache():
    """ì„œë²„ ì‹œì‘ ì‹œ ë°±ê·¸ë¼ìš´ë“œë¡œ ìºì‹œ ë¯¸ë¦¬ ë¡œë“œ"""
    try:
        _cache["loading"] = True
        _get_cached_data()
    except Exception as e:
        logger.error(f"âŒ ìºì‹œ í”„ë¦¬ë¡œë“œ ì‹¤íŒ¨: {e}")
    finally:
        _cache["loading"] = False


def _load_and_prepare(excel_path: str) -> pd.DataFrame:
    """ì—‘ì…€ ë¡œë“œ + ê¸°ë³¸ ì „ì²˜ë¦¬"""
    df = pd.read_excel(excel_path)

    # NaN ì²˜ë¦¬ (ë¹ˆ ì¹¸ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜)
    text_cols = ['ì„±ë¶„ëª…', 'ì‹ ì²­ì¸', 'ì œì¡°ì†Œëª…', 'ì œì¡°êµ­ê°€', 'ë“±ë¡ë²ˆí˜¸',
                 'ì·¨ì†Œ/ì·¨í•˜êµ¬ë¶„', 'ì—°ê³„ì‹¬ì‚¬ë¬¸ì„œë²ˆí˜¸']
    for col in text_cols:
        if col in df.columns:
            df[col] = df[col].fillna('')

    df['ìµœì´ˆë“±ë¡ì¼ì'] = pd.to_datetime(df['ìµœì´ˆë“±ë¡ì¼ì'], errors='coerce')

    df['is_í—ˆì—¬'] = df['ë“±ë¡ë²ˆí˜¸'].astype(str).str.contains(r'\(', na=False)
    df['ë“±ë¡ìœ í˜•'] = df['is_í—ˆì—¬'].map({True: 'í—ˆì—¬(ë³€ê²½)', False: 'ìµœì´ˆë“±ë¡'})

    df['base_dmf'] = df['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
        lambda x: x.split('(', 1)[0] if '(' in x else x
    )
    has_linked = (df['ì—°ê³„ì‹¬ì‚¬ë¬¸ì„œë²ˆí˜¸'].astype(str).str.strip() != '')
    linked_bases = set(df.loc[has_linked, 'base_dmf'])
    df['has_ì—°ê³„ì‹¬ì‚¬'] = df['base_dmf'].isin(linked_bases)

    active = df[df['ì·¨ì†Œ/ì·¨í•˜êµ¬ë¶„'] == 'ì •ìƒ'].copy()
    return active


# â”€â”€â”€ ë¶„ì„ í•¨ìˆ˜ë“¤ (JSON dict ë°˜í™˜) â”€â”€â”€

def analyze_weekly_dmf(weeks_ago: int = 1) -> dict:
    """ì£¼ê°„ DMF ë“±ë¡ í˜„í™© ë¶„ì„"""
    try:
        active = _get_cached_data()

        today = datetime.today()
        days_since_monday = today.weekday()
        this_monday = today - timedelta(days=days_since_monday)
        target_monday = this_monday - timedelta(weeks=weeks_ago)
        target_friday = target_monday + timedelta(days=4)

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(target_monday)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(target_friday))
        week_df = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        week_label = f"{target_monday.strftime('%m/%d')}~{target_friday.strftime('%m/%d')}"

        if len(week_df) == 0:
            return {"ê¸°ê°„": week_label, "ë©”ì‹œì§€": "í•´ë‹¹ ì£¼ê°„ ì‹ ê·œ DMF ë“±ë¡ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        details = []
        for _, row in week_df.iterrows():
            details.append({
                "ë“±ë¡ì¼": row['ìµœì´ˆë“±ë¡ì¼ì'].strftime('%m/%d'),
                "ë“±ë¡ìœ í˜•": 'í—ˆì—¬' if row['is_í—ˆì—¬'] else 'ìµœì´ˆ',
                "ì„±ë¶„ëª…": str(row.get('ì„±ë¶„ëª…', '')),
                "ì‹ ì²­ì¸": str(row.get('ì‹ ì²­ì¸', '')),
                "ì œì¡°ì†Œ": str(row.get('ì œì¡°ì†Œëª…', ''))[:25],
                "êµ­ê°€": str(row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/'),
                "ì—°ê³„ì‹¬ì‚¬": 'O' if row['has_ì—°ê³„ì‹¬ì‚¬'] else 'X'
            })

        return {
            "ê¸°ê°„": week_label,
            "ì´ê±´ìˆ˜": len(week_df),
            "ìµœì´ˆë“±ë¡": int((~week_df['is_í—ˆì—¬']).sum()),
            "í—ˆì—¬_ë³€ê²½": int(week_df['is_í—ˆì—¬'].sum()),
            "ì—°ê³„ì‹¬ì‚¬_ìˆìŒ": int(week_df['has_ì—°ê³„ì‹¬ì‚¬'].sum()),
            "ìƒì„¸ë‚´ì—­": details
        }
    except Exception as e:
        logger.error(f"ì£¼ê°„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise


def analyze_monthly_dmf(months_ago: int = 1) -> dict:
    """ì›”ê°„ DMF ë“±ë¡ í˜„í™© ë¶„ì„"""
    try:
        active = _get_cached_data()

        today = datetime.today()
        target_end = today.replace(day=1) - timedelta(days=1)
        for _ in range(months_ago - 1):
            target_end = target_end.replace(day=1) - timedelta(days=1)
        target_start = target_end.replace(day=1)

        month_label = target_start.strftime('%Yë…„ %mì›”')

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(target_start)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(target_end))
        month_df = active[mask]

        prev_end = target_start - timedelta(days=1)
        prev_start = prev_end.replace(day=1)
        prev_mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(prev_start)) & \
                    (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(prev_end))
        prev_count = int(active[prev_mask].shape[0])

        if prev_count > 0:
            change_pct = (len(month_df) - prev_count) / prev_count * 100
            change_str = f"+{change_pct:.1f}%" if change_pct >= 0 else f"{change_pct:.1f}%"
        else:
            change_str = "N/A"

        countries = []
        for c in month_df['ì œì¡°êµ­ê°€'].dropna():
            for cc in str(c).split('@'):
                countries.append(cc.strip())
        country_counts = Counter(countries).most_common(10)
        total_c = sum(dict(country_counts).values()) if country_counts else 1
        country_list = [
            {"êµ­ê°€": c, "ê±´ìˆ˜": n, "ë¹„ìœ¨": f"{n/total_c*100:.1f}%"}
            for c, n in country_counts
        ]

        top_applicants = month_df.groupby('ì‹ ì²­ì¸').agg(
            ê±´ìˆ˜=('ë“±ë¡ë²ˆí˜¸', 'count')
        ).sort_values('ê±´ìˆ˜', ascending=False).head(5)
        applicant_list = [
            {"ì‹ ì²­ì¸": name, "ê±´ìˆ˜": int(row['ê±´ìˆ˜'])}
            for name, row in top_applicants.iterrows()
        ]

        return {
            "ê¸°ê°„": month_label,
            "ì´ê±´ìˆ˜": len(month_df),
            "ìµœì´ˆë“±ë¡": int((~month_df['is_í—ˆì—¬']).sum()),
            "í—ˆì—¬_ë³€ê²½": int(month_df['is_í—ˆì—¬'].sum()),
            "ì „ì›”ëŒ€ë¹„_ë³€ë™": change_str,
            "ì „ì›”_ê±´ìˆ˜": prev_count,
            "êµ­ê°€ë³„_ë¶„í¬": country_list,
            "ì£¼ìš”_ì‹ ì²­ì¸_TOP5": applicant_list
        }
    except Exception as e:
        logger.error(f"ì›”ê°„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise


def search_ingredient(ingredient: str, linked_filter: str = None) -> dict:
    """
    ì„±ë¶„ëª…ìœ¼ë¡œ DMF ê²€ìƒ‰
    
    Args:
        ingredient: ê²€ìƒ‰ í‚¤ì›Œë“œ (ë¶€ë¶„ ë§¤ì¹­)
        linked_filter: 'linked' = ì—°ê³„ì‹¬ì‚¬ ìˆëŠ” ê²ƒë§Œ, 'unlinked' = ì—†ëŠ” ê²ƒë§Œ, None = ì „ì²´
    """
    try:
        active = _get_cached_data()

        mask = active['ì„±ë¶„ëª…'].astype(str).str.contains(ingredient, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return {"ê²€ìƒ‰ì–´": ingredient, "ë©”ì‹œì§€": f"'{ingredient}' ê´€ë ¨ DMF ë“±ë¡ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        found_copy = found.copy()
        found_copy['base_dmf'] = found_copy['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
            lambda x: x.split('(')[0] if '(' in x else x
        )

        # ì„±ë¶„ëª…ë³„ë¡œ ê·¸ë£¹í•‘ (ë™ì¼ í‚¤ì›Œë“œë¼ë„ ë‹¤ë¥¸ ì„±ë¶„ì€ ë¶„ë¦¬)
        ingredient_groups = []
        total_mfr_count = 0
        total_linked_count = 0

        for ing_name, ing_group in found_copy.groupby('ì„±ë¶„ëª…'):
            # ì´ ì„±ë¶„ì˜ ì œì¡°ì›ë³„ ë¶„ì„
            manufacturers = []
            for base, group in ing_group.groupby('base_dmf'):
                first_row = group[~group['is_í—ˆì—¬']]
                if len(first_row) == 0:
                    first_row = group.iloc[:1]
                first_row = first_row.iloc[0]

                heo_count = int(group['is_í—ˆì—¬'].sum())
                is_linked = bool(first_row['has_ì—°ê³„ì‹¬ì‚¬'])
                status = 'ì •ìƒ' if (group['ì·¨ì†Œ/ì·¨í•˜êµ¬ë¶„'] == 'ì •ìƒ').any() else 'ì·¨ì†Œ/ì·¨í•˜'

                mfr_data = {
                    "base_dmf": base,
                    "ì œì¡°ì†Œ": str(first_row.get('ì œì¡°ì†Œëª…', '')),
                    "êµ­ê°€": str(first_row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/'),
                    "ì‹ ì²­ì¸": str(first_row.get('ì‹ ì²­ì¸', '')),
                    "ë“±ë¡ì¼": first_row['ìµœì´ˆë“±ë¡ì¼ì'].strftime('%Y-%m-%d') if pd.notna(first_row['ìµœì´ˆë“±ë¡ì¼ì']) else '',
                    "í—ˆì—¬_ìˆ˜": heo_count,
                    "ì—°ê³„ì‹¬ì‚¬": is_linked,
                    "ìƒíƒœ": status
                }

                # í•„í„° ì ìš©
                if linked_filter == 'linked' and not is_linked:
                    continue
                if linked_filter == 'unlinked' and is_linked:
                    continue

                manufacturers.append(mfr_data)

            if not manufacturers:
                continue

            linked_count = sum(1 for m in manufacturers if m['ì—°ê³„ì‹¬ì‚¬'])
            total_mfr_count += len(manufacturers)
            total_linked_count += linked_count

            # êµ­ê°€ë³„ ë¶„í¬
            country_dist = Counter()
            for m in manufacturers:
                main_country = m['êµ­ê°€'].split('/')[0]
                country_dist[main_country] += 1

            ingredient_groups.append({
                "ì„±ë¶„ëª…": str(ing_name),
                "ì œì¡°ì›ìˆ˜": len(manufacturers),
                "ì—°ê³„ì‹¬ì‚¬_ìˆ˜": linked_count,
                "êµ­ê°€ë³„_ë¶„í¬": [{"êµ­ê°€": k, "ìˆ˜": v} for k, v in country_dist.most_common()],
                "ì œì¡°ì›_ëª©ë¡": manufacturers
            })

        if not ingredient_groups:
            filter_msg = "ì—°ê³„ì‹¬ì‚¬ ë“±ë¡ëœ" if linked_filter == 'linked' else "ì—°ê³„ì‹¬ì‚¬ ë¯¸ë“±ë¡"
            return {"ê²€ìƒ‰ì–´": ingredient, "ë©”ì‹œì§€": f"'{ingredient}' ì¤‘ {filter_msg} ì œì¡°ì›ì´ ì—†ìŠµë‹ˆë‹¤.", "ì´ê±´ìˆ˜": 0}

        return {
            "ê²€ìƒ‰ì–´": ingredient,
            "í•„í„°": linked_filter,
            "ì„±ë¶„_ì¢…ë¥˜ìˆ˜": len(ingredient_groups),
            "ì´_ì œì¡°ì›ìˆ˜": total_mfr_count,
            "ì´_ì—°ê³„ì‹¬ì‚¬ìˆ˜": total_linked_count,
            "ì„±ë¶„ë³„_í˜„í™©": ingredient_groups
        }
    except Exception as e:
        logger.error(f"ì„±ë¶„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def search_country(country: str) -> dict:
    """êµ­ê°€ë³„ DMF ê²€ìƒ‰"""
    try:
        active = _get_cached_data()

        mask = active['ì œì¡°êµ­ê°€'].astype(str).str.contains(country, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return {"ê²€ìƒ‰_êµ­ê°€": country, "ë©”ì‹œì§€": f"'{country}' ê´€ë ¨ DMF ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        three_months_ago = datetime.today() - timedelta(days=90)
        recent = found[found['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(three_months_ago)]

        top_ingredients = found['ì„±ë¶„ëª…'].value_counts().head(10)
        ingredient_list = [
            {"ì„±ë¶„ëª…": name, "ê±´ìˆ˜": int(cnt)}
            for name, cnt in top_ingredients.items()
        ]

        top_mfrs = found['ì œì¡°ì†Œëª…'].value_counts().head(10)
        mfr_list = [
            {"ì œì¡°ì†Œ": name, "ê±´ìˆ˜": int(cnt)}
            for name, cnt in top_mfrs.items()
        ]

        return {
            "ê²€ìƒ‰_êµ­ê°€": country,
            "ì „ì²´_ë“±ë¡ê±´ìˆ˜": len(found),
            "ìµœê·¼3ê°œì›”_ì‹ ê·œ": len(recent),
            "ì£¼ìš”_ì„±ë¶„_TOP10": ingredient_list,
            "ì£¼ìš”_ì œì¡°ì†Œ_TOP10": mfr_list
        }
    except Exception as e:
        logger.error(f"êµ­ê°€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def search_applicant(applicant: str, month: int = None) -> dict:
    """ì‹ ì²­ì¸ë³„ DMF ê²€ìƒ‰"""
    try:
        active = _get_cached_data()

        mask = active['ì‹ ì²­ì¸'].astype(str).str.contains(applicant, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return {"ê²€ìƒ‰_ì‹ ì²­ì¸": applicant, "ë©”ì‹œì§€": f"'{applicant}' ê´€ë ¨ DMF ë“±ë¡ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        # ì›” í•„í„°
        if month:
            year = datetime.today().year
            found_month = found[
                (found['ìµœì´ˆë“±ë¡ì¼ì'].dt.month == month) &
                (found['ìµœì´ˆë“±ë¡ì¼ì'].dt.year == year)
            ]
            month_label = f"{year}ë…„ {month}ì›”"
        else:
            found_month = found
            month_label = "ì „ì²´"

        # ì„±ë¶„ë³„ í˜„í™©
        ingredient_list = []
        for name, group in found_month.groupby('ì„±ë¶„ëª…'):
            group_copy = group.copy()
            group_copy['base_dmf'] = group_copy['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
                lambda x: x.split('(')[0] if '(' in x else x
            )
            mfr_count = group_copy['base_dmf'].nunique()

            # ì œì¡°ì†Œ ëª©ë¡
            mfrs = []
            for base, bg in group_copy.groupby('base_dmf'):
                first = bg[~bg['is_í—ˆì—¬']]
                if len(first) == 0:
                    first = bg.iloc[:1]
                first = first.iloc[0]
                mfrs.append({
                    "ì œì¡°ì†Œ": str(first.get('ì œì¡°ì†Œëª…', '')),
                    "êµ­ê°€": str(first.get('ì œì¡°êµ­ê°€', '')).replace('@', '/'),
                    "ë“±ë¡ì¼": first['ìµœì´ˆë“±ë¡ì¼ì'].strftime('%Y-%m-%d') if pd.notna(first['ìµœì´ˆë“±ë¡ì¼ì']) else ''
                })

            ingredient_list.append({
                "ì„±ë¶„ëª…": str(name),
                "ë“±ë¡ê±´ìˆ˜": len(group),
                "ì œì¡°ì›ìˆ˜": mfr_count,
                "ì œì¡°ì›": mfrs
            })

        # ì œì¡°êµ­ê°€ ë¶„í¬
        country_dist = Counter()
        for _, row in found_month.iterrows():
            main_country = str(row['ì œì¡°êµ­ê°€']).split('@')[0]
            country_dist[main_country] += 1
        country_list = [{"êµ­ê°€": k, "ê±´ìˆ˜": v} for k, v in country_dist.most_common()]

        return {
            "ê²€ìƒ‰_ì‹ ì²­ì¸": applicant,
            "ê¸°ê°„": month_label,
            "ì´_ë“±ë¡ê±´ìˆ˜": len(found_month),
            "ì·¨ê¸‰_ì„±ë¶„ìˆ˜": len(ingredient_list),
            "êµ­ê°€ë³„_ë¶„í¬": country_list,
            "ì„±ë¶„ë³„_í˜„í™©": sorted(ingredient_list, key=lambda x: x['ë“±ë¡ê±´ìˆ˜'], reverse=True)
        }
    except Exception as e:
        logger.error(f"ì‹ ì²­ì¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def search_manufacturer(keyword: str) -> dict:
    """ì œì¡°ì†Œëª…ìœ¼ë¡œ DMF ê²€ìƒ‰"""
    try:
        active = _get_cached_data()

        mask = active['ì œì¡°ì†Œëª…'].astype(str).str.contains(keyword, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return {"ê²€ìƒ‰_ì œì¡°ì†Œ": keyword, "ë©”ì‹œì§€": f"'{keyword}' ê´€ë ¨ ì œì¡°ì†Œ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        found_copy = found.copy()
        found_copy['base_dmf'] = found_copy['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
            lambda x: x.split('(')[0] if '(' in x else x
        )

        # ì„±ë¶„ë³„ í˜„í™©
        ingredient_list = []
        for name, group in found_copy.groupby('ì„±ë¶„ëª…'):
            mfr_count = group['base_dmf'].nunique()
            linked_count = group[group['has_ì—°ê³„ì‹¬ì‚¬']]['base_dmf'].nunique()
            applicants = group['ì‹ ì²­ì¸'].unique().tolist()

            ingredient_list.append({
                "ì„±ë¶„ëª…": str(name),
                "ì œì¡°ì›ìˆ˜": mfr_count,
                "ì—°ê³„ì‹¬ì‚¬_ìˆ˜": linked_count,
                "ì‹ ì²­ì¸": [a for a in applicants if a][:3]
            })

        # êµ­ê°€ ì •ë³´
        country_dist = Counter()
        for _, row in found_copy.drop_duplicates('base_dmf').iterrows():
            main_country = str(row['ì œì¡°êµ­ê°€']).split('@')[0]
            country_dist[main_country] += 1

        return {
            "ê²€ìƒ‰_ì œì¡°ì†Œ": keyword,
            "ì´_ë“±ë¡ê±´ìˆ˜": len(found),
            "ì·¨ê¸‰_ì„±ë¶„ìˆ˜": len(ingredient_list),
            "êµ­ê°€ë³„_ë¶„í¬": [{"êµ­ê°€": k, "ê±´ìˆ˜": v} for k, v in country_dist.most_common()],
            "ì„±ë¶„ë³„_í˜„í™©": sorted(ingredient_list, key=lambda x: x['ì œì¡°ì›ìˆ˜'], reverse=True)
        }
    except Exception as e:
        logger.error(f"ì œì¡°ì†Œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def search_universal(keyword: str, month: int = None) -> tuple:
    """
    í†µí•© ê²€ìƒ‰: ì„±ë¶„ëª… â†’ ì‹ ì²­ì¸ â†’ ì œì¡°ì†Œëª… ìˆœì„œë¡œ ê²€ìƒ‰
    Returns: (search_type, data) íŠœí”Œ
        search_type: 'ingredient' | 'applicant' | 'manufacturer' | 'none'
    """
    active = _get_cached_data()

    # 1ìˆœìœ„: ì„±ë¶„ëª…
    if active['ì„±ë¶„ëª…'].astype(str).str.contains(keyword, case=False, na=False).any():
        return ('ingredient', None)  # ê¸°ì¡´ search_ingredient ì‚¬ìš©

    # 2ìˆœìœ„: ì‹ ì²­ì¸
    if active['ì‹ ì²­ì¸'].astype(str).str.contains(keyword, case=False, na=False).any():
        return ('applicant', search_applicant(keyword, month))

    # 3ìˆœìœ„: ì œì¡°ì†Œëª…
    if active['ì œì¡°ì†Œëª…'].astype(str).str.contains(keyword, case=False, na=False).any():
        return ('manufacturer', search_manufacturer(keyword))

    return ('none', None)


def search_date_range(start_date, end_date) -> dict:
    """ê¸°ê°„ë³„ DMF ë“±ë¡ í˜„í™© ê²€ìƒ‰"""
    try:
        active = _get_cached_data()

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(start_date)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(end_date))
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        period_label = f"{start_date.strftime('%m/%d')}~{end_date.strftime('%m/%d')}"

        if len(found) == 0:
            return {"ê¸°ê°„": period_label, "ë©”ì‹œì§€": f"{period_label} ê¸°ê°„ ì‹ ê·œ DMF ë“±ë¡ ì—†ìŒ", "ì´ê±´ìˆ˜": 0}

        initial = int((~found['is_í—ˆì—¬']).sum())
        change = int(found['is_í—ˆì—¬'].sum())
        linked = int(found['has_ì—°ê³„ì‹¬ì‚¬'].sum())

        # êµ­ê°€ë³„ ë¶„í¬
        country_dist = Counter()
        for _, row in found.iterrows():
            main_country = str(row['ì œì¡°êµ­ê°€']).split('@')[0]
            country_dist[main_country] += 1
        country_list = [{"êµ­ê°€": k, "ê±´ìˆ˜": v} for k, v in country_dist.most_common()]

        # ì„±ë¶„ë³„ ëª©ë¡
        ingredient_list = []
        for name, group in found.groupby('ì„±ë¶„ëª…'):
            ingredient_list.append({
                "ì„±ë¶„ëª…": str(name),
                "ê±´ìˆ˜": len(group),
                "ì‹ ì²­ì¸": group['ì‹ ì²­ì¸'].iloc[0] if len(group) > 0 else '',
                "ì œì¡°ì†Œ": group['ì œì¡°ì†Œëª…'].iloc[0][:20] if len(group) > 0 else '',
                "êµ­ê°€": str(group['ì œì¡°êµ­ê°€'].iloc[0]).split('@')[0] if len(group) > 0 else ''
            })
        ingredient_list.sort(key=lambda x: x['ê±´ìˆ˜'], reverse=True)

        return {
            "ê¸°ê°„": period_label,
            "ì´ê±´ìˆ˜": len(found),
            "ìµœì´ˆë“±ë¡": initial,
            "í—ˆì—¬": change,
            "ì—°ê³„ì‹¬ì‚¬": linked,
            "êµ­ê°€ë³„_ë¶„í¬": country_list,
            "ì„±ë¶„ë³„_í˜„í™©": ingredient_list
        }
    except Exception as e:
        logger.error(f"ê¸°ê°„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def generate_chat_summary() -> str:
    """ì¹´ì¹´ì˜¤í†¡ ê³µìœ ìš© ê°„ê²°í•œ ìš”ì•½ ë©”ì‹œì§€"""
    try:
        active = _get_cached_data()

        today = datetime.today()
        days_since_monday = today.weekday()
        this_monday = today - timedelta(days=days_since_monday)
        last_monday = this_monday - timedelta(days=7)
        last_friday = last_monday + timedelta(days=4)

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(last_monday)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(last_friday))
        week_df = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        week_label = f"{last_monday.strftime('%m/%d')}~{last_friday.strftime('%m/%d')}"

        lines = []
        lines.append(f"ğŸ“‹ DMF ì£¼ê°„ í˜„í™© ({week_label})")
        lines.append(f"{'='*28}")

        if len(week_df) == 0:
            lines.append("í•´ë‹¹ ì£¼ê°„ ì‹ ê·œ DMF ë“±ë¡ ì—†ìŒ")
        else:
            initial = int((~week_df['is_í—ˆì—¬']).sum())
            change = int(week_df['is_í—ˆì—¬'].sum())
            linked = int(week_df['has_ì—°ê³„ì‹¬ì‚¬'].sum())

            lines.append(f"ì´ {len(week_df)}ê±´ (ìµœì´ˆ {initial} / í—ˆì—¬ {change})")
            lines.append(f"ì—°ê³„ì‹¬ì‚¬ {linked}ê±´")
            lines.append("")

            for _, row in week_df.iterrows():
                reg_type = "ğŸ”µìµœì´ˆ" if not row['is_í—ˆì—¬'] else "ğŸŸ¡í—ˆì—¬"
                linked_mark = "âœ…" if row['has_ì—°ê³„ì‹¬ì‚¬'] else ""
                country = str(row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/').strip()
                ingredient = str(row.get('ì„±ë¶„ëª…', ''))
                applicant = str(row.get('ì‹ ì²­ì¸', ''))

                lines.append(f"{reg_type} {ingredient}")
                lines.append(f"  {applicant} | {country} {linked_mark}")

            lines.append("")
            lines.append("ì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ DMF ì‹¬ì‚¬ê²°ê³¼")

        return "\n".join(lines)
    except Exception as e:
        logger.error(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        raise


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# [1] MCP ì„œë²„ ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if MCP_AVAILABLE:
    mcp = FastMCP(
        "dmf-intelligence",
        instructions="""DMF(Drug Master File) ë“±ë¡ í˜„í™©ì„ ì¡°íšŒÂ·ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
        ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼(nedrug.mfds.go.kr)ì˜ ê³µê°œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        ì‹ ê·œ DMF ë“±ë¡, êµ­ê°€ë³„/ì„±ë¶„ë³„ ë¶„ì„, ê²½ìŸ ë™í–¥ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    )

    @mcp.tool()
    def get_weekly_dmf(weeks_ago: int = 1) -> str:
        """ìµœê·¼ ì£¼ê°„ DMF ë“±ë¡ í˜„í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            return json.dumps(analyze_weekly_dmf(weeks_ago), ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    @mcp.tool()
    def get_monthly_dmf_summary(months_ago: int = 1) -> str:
        """ì›”ê°„ DMF ë“±ë¡ í˜„í™© ìš”ì•½ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            return json.dumps(analyze_monthly_dmf(months_ago), ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    @mcp.tool()
    def search_dmf_by_ingredient(ingredient: str) -> str:
        """íŠ¹ì • ì„±ë¶„ëª…ìœ¼ë¡œ DMF ë“±ë¡ í˜„í™©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            return json.dumps(search_ingredient(ingredient), ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    @mcp.tool()
    def search_dmf_by_country(country: str) -> str:
        """íŠ¹ì • êµ­ê°€ì˜ DMF ë“±ë¡ í˜„í™©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            return json.dumps(search_country(country), ensure_ascii=False, indent=2)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    @mcp.tool()
    def get_dmf_chat_summary() -> str:
        """ì¹´ì¹´ì˜¤í†¡ ê³µìœ ìš© ê°„ê²°í•œ DMF ìš”ì•½ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            return generate_chat_summary()
        except Exception as e:
            return f"âŒ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# [2] ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë” Skill ì›¹í›… API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@asynccontextmanager
async def lifespan(app):
    """ì„œë²„ ì‹œì‘ ì‹œ ìºì‹œ í”„ë¦¬ë¡œë“œ"""
    thread = threading.Thread(target=_preload_cache, daemon=True)
    thread.start()
    logger.info("ğŸš€ ë°±ê·¸ë¼ìš´ë“œ ìºì‹œ í”„ë¦¬ë¡œë“œ ì‹œì‘")
    yield

app = FastAPI(title="DMF Intelligence Server", version="2.0", lifespan=lifespan)


def kakao_simple_text(text: str) -> dict:
    """ì¹´ì¹´ì˜¤ ì˜¤í”ˆë¹Œë” simpleText ì‘ë‹µ ìƒì„±"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [
                {"simpleText": {"text": text}}
            ]
        }
    }


def kakao_text_with_buttons(text: str, buttons: list) -> dict:
    """ì¹´ì¹´ì˜¤ ì˜¤í”ˆë¹Œë” í…ìŠ¤íŠ¸ + ë²„íŠ¼ ì‘ë‹µ ìƒì„±"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [
                {
                    "basicCard": {
                        "description": text,
                        "buttons": buttons
                    }
                }
            ]
        }
    }


def kakao_quick_replies(text: str, replies: list) -> dict:
    """ì¹´ì¹´ì˜¤ ì˜¤í”ˆë¹Œë” í…ìŠ¤íŠ¸ + ë°”ë¡œê°€ê¸° ì‘ë‹µ ìƒì„±"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [
                {"simpleText": {"text": text}}
            ],
            "quickReplies": replies
        }
    }


def format_weekly_for_kakao(data: dict) -> str:
    """ì£¼ê°„ ë¶„ì„ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì´ê±´ìˆ˜", 0) == 0:
        return f"ğŸ“‹ DMF ì£¼ê°„ í˜„í™© ({data['ê¸°ê°„']})\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸ“‹ DMF ì£¼ê°„ í˜„í™© ({data['ê¸°ê°„']})",
        f"{'â”€'*24}",
        f"ì´ {data['ì´ê±´ìˆ˜']}ê±´ (ìµœì´ˆ {data['ìµœì´ˆë“±ë¡']} / í—ˆì—¬ {data['í—ˆì—¬_ë³€ê²½']})",
        f"ì—°ê³„ì‹¬ì‚¬ {data['ì—°ê³„ì‹¬ì‚¬_ìˆìŒ']}ê±´",
        ""
    ]

    for item in data.get("ìƒì„¸ë‚´ì—­", [])[:15]:  # ì¹´ì¹´ì˜¤í†¡ ê¸€ììˆ˜ ì œí•œ ê³ ë ¤
        reg_icon = "ğŸ”µ" if item['ë“±ë¡ìœ í˜•'] == 'ìµœì´ˆ' else "ğŸŸ¡"
        linked = " âœ…" if item['ì—°ê³„ì‹¬ì‚¬'] == 'O' else ""
        lines.append(f"{reg_icon} {item['ì„±ë¶„ëª…']}")
        lines.append(f"  {item['ì‹ ì²­ì¸']} | {item['êµ­ê°€']}{linked}")

    if len(data.get("ìƒì„¸ë‚´ì—­", [])) > 15:
        lines.append(f"\n... ì™¸ {len(data['ìƒì„¸ë‚´ì—­']) - 15}ê±´")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_monthly_for_kakao(data: dict) -> str:
    """ì›”ê°„ ë¶„ì„ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    lines = [
        f"ğŸ“Š DMF ì›”ê°„ ë¦¬í¬íŠ¸ ({data['ê¸°ê°„']})",
        f"{'â”€'*24}",
        f"ì´ {data['ì´ê±´ìˆ˜']}ê±´ (ì „ì›” {data['ì „ì›”_ê±´ìˆ˜']}ê±´, {data['ì „ì›”ëŒ€ë¹„_ë³€ë™']})",
        f"  ìµœì´ˆë“±ë¡ {data['ìµœì´ˆë“±ë¡']}ê±´ / í—ˆì—¬ {data['í—ˆì—¬_ë³€ê²½']}ê±´",
        ""
    ]

    if data.get("êµ­ê°€ë³„_ë¶„í¬"):
        lines.append("ğŸŒ êµ­ê°€ë³„ ë¶„í¬:")
        for item in data["êµ­ê°€ë³„_ë¶„í¬"][:5]:
            lines.append(f"  {item['êµ­ê°€']}: {item['ê±´ìˆ˜']}ê±´ ({item['ë¹„ìœ¨']})")

    if data.get("ì£¼ìš”_ì‹ ì²­ì¸_TOP5"):
        lines.append("\nğŸ‘¤ ì£¼ìš” ì‹ ì²­ì¸:")
        for item in data["ì£¼ìš”_ì‹ ì²­ì¸_TOP5"]:
            lines.append(f"  {item['ì‹ ì²­ì¸']}: {item['ê±´ìˆ˜']}ê±´")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_ingredient_for_kakao(data: dict) -> str:
    """ì„±ë¶„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§· (ì„±ë¶„ëª…ë³„ ê·¸ë£¹í•‘)"""
    if data.get("ì´ê±´ìˆ˜", 0) == 0 and data.get("ì´_ì œì¡°ì›ìˆ˜", 0) == 0:
        return f"ğŸ” '{data['ê²€ìƒ‰ì–´']}' ê²€ìƒ‰ ê²°ê³¼\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    linked_filter = data.get("í•„í„°")
    filter_label = ""
    if linked_filter == 'linked':
        filter_label = " [ì—°ê³„ì‹¬ì‚¬ âœ…]"
    elif linked_filter == 'unlinked':
        filter_label = " [ë¯¸ì—°ê³„]"

    lines = [
        f"ğŸ” '{data['ê²€ìƒ‰ì–´']}' DMF í˜„í™©{filter_label}",
        f"{'â”€'*24}",
        f"ğŸ“‹ ì„±ë¶„ {data['ì„±ë¶„_ì¢…ë¥˜ìˆ˜']}ì¢… | ì œì¡°ì› {data['ì´_ì œì¡°ì›ìˆ˜']}ê°œì‚¬ | ì—°ê³„ {data['ì´_ì—°ê³„ì‹¬ì‚¬ìˆ˜']}ê°œ",
    ]

    # ì„±ë¶„ë³„ ìƒì„¸
    for ig in data.get("ì„±ë¶„ë³„_í˜„í™©", []):
        lines.append(f"\n{'â”'*24}")
        lines.append(f"ğŸ’Š {ig['ì„±ë¶„ëª…']}")

        # êµ­ê°€ë³„ ë¶„í¬
        dist = ig.get("êµ­ê°€ë³„_ë¶„í¬", [])
        if dist:
            dist_str = " | ".join([f"{c['êµ­ê°€']} {c['ìˆ˜']}" for c in dist[:4]])
            lines.append(f"   ğŸŒ {dist_str}")

        lines.append(f"   ì œì¡°ì› {ig['ì œì¡°ì›ìˆ˜']}ê°œ (ì—°ê³„ {ig['ì—°ê³„ì‹¬ì‚¬_ìˆ˜']}ê°œ)")

        # ì œì¡°ì› ëª©ë¡ (ì „ì²´ í‘œì‹œ, 1ì¤„ë¡œ ì••ì¶•)
        for m in ig.get("ì œì¡°ì›_ëª©ë¡", []):
            linked_mark = "âœ…" if m['ì—°ê³„ì‹¬ì‚¬'] else "â¬œ"
            status_mark = "âŒ" if m['ìƒíƒœ'] != 'ì •ìƒ' else ""
            heo = f"+{m['í—ˆì—¬_ìˆ˜']}í—ˆì—¬" if m['í—ˆì—¬_ìˆ˜'] > 0 else ""
            country = m['êµ­ê°€'].split('/')[0]  # ì²« ë²ˆì§¸ êµ­ê°€ë§Œ
            lines.append(f"  {linked_mark} {m['ì œì¡°ì†Œ'][:20]} ({country})")
            lines.append(f"     {m['ì‹ ì²­ì¸'][:12]} {heo}{status_mark}")

    lines.append(f"\n{'â”€'*24}")
    lines.append("ì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_country_for_kakao(data: dict) -> str:
    """êµ­ê°€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì „ì²´_ë“±ë¡ê±´ìˆ˜", 0) == 0:
        return f"ğŸŒ '{data['ê²€ìƒ‰_êµ­ê°€']}' ê²€ìƒ‰ ê²°ê³¼\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸŒ {data['ê²€ìƒ‰_êµ­ê°€']} DMF í˜„í™©",
        f"{'â”€'*24}",
        f"ì „ì²´ {data['ì „ì²´_ë“±ë¡ê±´ìˆ˜']}ê±´ (ìµœê·¼3ê°œì›” {data['ìµœê·¼3ê°œì›”_ì‹ ê·œ']}ê±´)",
        ""
    ]

    if data.get("ì£¼ìš”_ì„±ë¶„_TOP10"):
        lines.append("ğŸ’Š ì£¼ìš” ì„±ë¶„:")
        for item in data["ì£¼ìš”_ì„±ë¶„_TOP10"][:7]:
            lines.append(f"  {item['ì„±ë¶„ëª…']}: {item['ê±´ìˆ˜']}ê±´")

    if data.get("ì£¼ìš”_ì œì¡°ì†Œ_TOP10"):
        lines.append("\nğŸ­ ì£¼ìš” ì œì¡°ì†Œ:")
        for item in data["ì£¼ìš”_ì œì¡°ì†Œ_TOP10"][:5]:
            lines.append(f"  {item['ì œì¡°ì†Œ'][:25]}: {item['ê±´ìˆ˜']}ê±´")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_applicant_for_kakao(data: dict) -> str:
    """ì‹ ì²­ì¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì´_ë“±ë¡ê±´ìˆ˜", 0) == 0:
        return f"ğŸ‘¤ '{data['ê²€ìƒ‰_ì‹ ì²­ì¸']}' ê²€ìƒ‰ ê²°ê³¼\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸ‘¤ '{data['ê²€ìƒ‰_ì‹ ì²­ì¸']}' DMF í˜„í™©",
        f"   ({data['ê¸°ê°„']})",
        f"{'â”€'*24}",
        f"ğŸ“‹ ì´ {data['ì´_ë“±ë¡ê±´ìˆ˜']}ê±´ | ì·¨ê¸‰ ì„±ë¶„ {data['ì·¨ê¸‰_ì„±ë¶„ìˆ˜']}ì¢…",
    ]

    # êµ­ê°€ë³„ ë¶„í¬
    country_dist = data.get("êµ­ê°€ë³„_ë¶„í¬", [])
    if country_dist:
        dist_str = " | ".join([f"{c['êµ­ê°€']} {c['ê±´ìˆ˜']}" for c in country_dist[:4]])
        lines.append(f"ğŸŒ {dist_str}")

    lines.append(f"{'â”€'*24}")

    # ì„±ë¶„ë³„ í˜„í™©
    ingredients = data.get("ì„±ë¶„ë³„_í˜„í™©", [])
    if ingredients:
        for item in ingredients[:8]:
            lines.append(f"\nğŸ’Š {item['ì„±ë¶„ëª…'][:20]}")
            lines.append(f"   ì œì¡°ì› {item['ì œì¡°ì›ìˆ˜']}ê°œì‚¬")
            for mfr in item.get('ì œì¡°ì›', [])[:3]:
                lines.append(f"   â–ª {mfr['ì œì¡°ì†Œ'][:22]} ({mfr['êµ­ê°€']})")

    if len(ingredients) > 8:
        lines.append(f"\n... ì™¸ {len(ingredients) - 8}ê°œ ì„±ë¶„")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_manufacturer_for_kakao(data: dict) -> str:
    """ì œì¡°ì†Œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì´ê±´ìˆ˜", 0) == 0:
        return f"ğŸ­ '{data['ê²€ìƒ‰_ì œì¡°ì†Œ']}' ê²€ìƒ‰ ê²°ê³¼\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸ­ '{data['ê²€ìƒ‰_ì œì¡°ì†Œ']}' ì œì¡°ì†Œ í˜„í™©",
        f"{'â”€'*24}",
        f"ğŸ“‹ ì´ {data['ì´_ë“±ë¡ê±´ìˆ˜']}ê±´ | ì·¨ê¸‰ ì„±ë¶„ {data['ì·¨ê¸‰_ì„±ë¶„ìˆ˜']}ì¢…",
    ]

    country_dist = data.get("êµ­ê°€ë³„_ë¶„í¬", [])
    if country_dist:
        dist_str = " | ".join([f"{c['êµ­ê°€']} {c['ê±´ìˆ˜']}" for c in country_dist[:4]])
        lines.append(f"ğŸŒ {dist_str}")

    lines.append(f"{'â”€'*24}")

    ingredients = data.get("ì„±ë¶„ë³„_í˜„í™©", [])
    if ingredients:
        for item in ingredients[:12]:
            linked_mark = f"âœ…{item['ì—°ê³„ì‹¬ì‚¬_ìˆ˜']}" if item['ì—°ê³„ì‹¬ì‚¬_ìˆ˜'] > 0 else "â¬œ0"
            apps = ", ".join(item.get('ì‹ ì²­ì¸', [])[:2])
            lines.append(f"ğŸ’Š {item['ì„±ë¶„ëª…'][:20]}")
            lines.append(f"   ì œì¡°ì› {item['ì œì¡°ì›ìˆ˜']}ê°œ | ì—°ê³„ {linked_mark} | {apps[:15]}")

    if len(ingredients) > 12:
        lines.append(f"\n... ì™¸ {len(ingredients) - 12}ê°œ ì„±ë¶„")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def format_date_range_for_kakao(data: dict) -> str:
    """ê¸°ê°„ë³„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ í˜•íƒœë¡œ í¬ë§·"""
    if data.get("ì´ê±´ìˆ˜", 0) == 0:
        return f"ğŸ“… {data['ê¸°ê°„']} DMF í˜„í™©\n\n{data.get('ë©”ì‹œì§€', 'ë“±ë¡ ì—†ìŒ')}"

    lines = [
        f"ğŸ“… {data['ê¸°ê°„']} DMF í˜„í™©",
        f"{'â”€'*24}",
        f"ì´ {data['ì´ê±´ìˆ˜']}ê±´ (ìµœì´ˆ {data['ìµœì´ˆë“±ë¡']} / í—ˆì—¬ {data['í—ˆì—¬']})",
        f"ì—°ê³„ì‹¬ì‚¬ {data['ì—°ê³„ì‹¬ì‚¬']}ê±´",
    ]

    country_dist = data.get("êµ­ê°€ë³„_ë¶„í¬", [])
    if country_dist:
        lines.append(f"\nğŸŒ êµ­ê°€ë³„:")
        for c in country_dist[:5]:
            lines.append(f"  {c['êµ­ê°€']}: {c['ê±´ìˆ˜']}ê±´")

    ingredients = data.get("ì„±ë¶„ë³„_í˜„í™©", [])
    if ingredients:
        lines.append(f"\nğŸ’Š ë“±ë¡ ì„±ë¶„:")
        for item in ingredients[:10]:
            lines.append(f"  {item['ì„±ë¶„ëª…'][:18]} ({item['êµ­ê°€']}) {item['ì‹ ì²­ì¸'][:8]}")

    if len(ingredients) > 10:
        lines.append(f"  ... ì™¸ {len(ingredients) - 10}ê°œ")

    lines.append("\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼")
    return "\n".join(lines)


def parse_intent_with_gemini(utterance: str) -> tuple:
    """
    Gemini Flashë¡œ ì‚¬ìš©ì ë°œí™” ì˜ë„ ë¶„ì„
    ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ â†’ regex fallback
    """
    api_key = os.environ.get("GEMINI_API_KEY", "")
    if not api_key:
        return None

    today = datetime.today()
    today_str = today.strftime('%Y-%m-%d')

    prompt = f"""ë‹¹ì‹ ì€ ì˜ì•½í’ˆ DMF(Drug Master File) ì±—ë´‡ì˜ ì¸í…íŠ¸ ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.
ì˜¤ëŠ˜ ë‚ ì§œ: {today_str}

ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ê°€ëŠ¥í•œ intent:
- "help": ì¸ì‚¬, ë„ì›€ë§, ì‚¬ìš©ë²• ì§ˆë¬¸
- "weekly": ì£¼ê°„ í˜„í™© ìš”ì²­
- "monthly": ì›”ê°„ í˜„í™© ìš”ì²­
- "summary": ìš”ì•½/ê³µìœ ìš© í…ìŠ¤íŠ¸ ìš”ì²­
- "date_range": íŠ¹ì • ê¸°ê°„ DMF í˜„í™© (start_date, end_date í¬í•¨, YYYY-MM-DD í˜•ì‹)
- "ingredient": ì„±ë¶„ëª…/ì œì¡°ì†Œ/ì‹ ì²­ì¸ ê²€ìƒ‰ (keyword í¬í•¨)
- "country": êµ­ê°€ë³„ DMF í˜„í™© (country í¬í•¨)
- "applicant": ì‹ ì²­ì¸ ì§€ì • ê²€ìƒ‰ (applicant + ì„ íƒì  month í¬í•¨)
- "analysis": ë°ì´í„° ë¶„ì„/í†µê³„/ì¡°ê±´ë¶€ ì§ˆë¬¸ (ì œì¡°ì›ìˆ˜ ëª‡ ê°œ ì´í•˜, ê°€ì¥ ë§ì€, ë¹„êµ, í†µê³„ ë“±)

ì¶”ê°€ íŒŒë¼ë¯¸í„°:
- keyword: ê²€ìƒ‰í•  í•µì‹¬ ë‹¨ì–´ (ì¡°ì‚¬/ë¶ˆí•„ìš” ë‹¨ì–´ ì œê±°)
- linked_filter: "linked" (ì—°ê³„ì‹¬ì‚¬ ëœ ê²ƒë§Œ), "unlinked" (ë¯¸ì—°ê³„ë§Œ), null (ì „ì²´)
- month: ì›” ìˆ«ì (ì—†ìœ¼ë©´ null)
- start_date, end_date: ê¸°ê°„ (YYYY-MM-DD, date_rangeì¼ ë•Œë§Œ)
- country: êµ­ê°€ëª… (countryì¼ ë•Œë§Œ)
- applicant: ì‹ ì²­ì¸ëª… (applicantì¼ ë•Œë§Œ)
- question: ì›ë˜ ì§ˆë¬¸ (analysisì¼ ë•Œë§Œ, ì›ë¬¸ ê·¸ëŒ€ë¡œ)

ì˜ˆì‹œ:
ì…ë ¥: "í´ë˜ë¦¬ ì—°ê³„ì‹¬ì‚¬ ëœ ì œì¡°ì›" â†’ {{"intent":"ingredient","keyword":"í´ë˜ë¦¬","linked_filter":"linked"}}
ì…ë ¥: "2ì›”9ì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ dmfí˜„í™©" â†’ {{"intent":"date_range","start_date":"{today.year}-02-09","end_date":"{today_str}"}}
ì…ë ¥: "1ì›”ì— íŒŒë§ˆí”¼ì•„ ë“±ë¡í˜„í™©" â†’ {{"intent":"applicant","applicant":"íŒŒë§ˆí”¼ì•„","month":1}}
ì…ë ¥: "íŒŒë§ˆí”¼ì•„" â†’ {{"intent":"ingredient","keyword":"íŒŒë§ˆí”¼ì•„"}}
ì…ë ¥: "ì¸ë„ DMF í˜„í™©" â†’ {{"intent":"country","country":"ì¸ë„"}}
ì…ë ¥: "ì˜¤ëŠ˜ ì‹ ê·œ ë“±ë¡" â†’ {{"intent":"date_range","start_date":"{today_str}","end_date":"{today_str}"}}
ì…ë ¥: "ìµœê·¼ 5ì¼ ë“±ë¡ í˜„í™©" â†’ {{"intent":"date_range","start_date":"{(today - timedelta(days=5)).strftime('%Y-%m-%d')}","end_date":"{today_str}"}}
ì…ë ¥: "Synthimed ì œì¡°ì†Œ ê²€ìƒ‰" â†’ {{"intent":"ingredient","keyword":"Synthimed"}}
ì…ë ¥: "ì„¸íŒŒí´ëŸ¬ ì¤‘ ì—°ê³„ ì•ˆëœ ì œì¡°ì› ì•Œë ¤ì¤˜" â†’ {{"intent":"ingredient","keyword":"ì„¸íŒŒí´ëŸ¬","linked_filter":"unlinked"}}
ì…ë ¥: "ì‹ ì²­ì¸ êµ­ì „ì•½í’ˆ 1ì›”" â†’ {{"intent":"applicant","applicant":"êµ­ì „ì•½í’ˆ","month":1}}
ì…ë ¥: "ì œì¡°ì›ìˆ˜ê°€ 3ê°œ ì´í•˜ì¸ í’ˆëª©ì€?" â†’ {{"intent":"analysis","question":"ì œì¡°ì›ìˆ˜ê°€ 3ê°œ ì´í•˜ì¸ í’ˆëª©ì€?"}}
ì…ë ¥: "ì—°ê³„ì‹¬ì‚¬ ë¹„ìœ¨ì´ ê°€ì¥ ë†’ì€ ì„±ë¶„ top 10" â†’ {{"intent":"analysis","question":"ì—°ê³„ì‹¬ì‚¬ ë¹„ìœ¨ì´ ê°€ì¥ ë†’ì€ ì„±ë¶„ top 10"}}
ì…ë ¥: "ì¤‘êµ­ ì œì¡°ì†Œê°€ ê°€ì¥ ë§ì€ ì„±ë¶„ì€?" â†’ {{"intent":"analysis","question":"ì¤‘êµ­ ì œì¡°ì†Œê°€ ê°€ì¥ ë§ì€ ì„±ë¶„ì€?"}}
ì…ë ¥: "ì˜¬í•´ ì‹ ê·œ ë“±ë¡ ê±´ìˆ˜ê°€ ê°€ì¥ ë§ì€ ì‹ ì²­ì¸ì€?" â†’ {{"intent":"analysis","question":"ì˜¬í•´ ì‹ ê·œ ë“±ë¡ ê±´ìˆ˜ê°€ ê°€ì¥ ë§ì€ ì‹ ì²­ì¸ì€?"}}
ì…ë ¥: "ì¸ë„ì™€ ì¤‘êµ­ ì œì¡°ì› ë¹„êµ" â†’ {{"intent":"analysis","question":"ì¸ë„ì™€ ì¤‘êµ­ ì œì¡°ì› ë¹„êµ"}}

ì‚¬ìš©ì ì…ë ¥: "{utterance}"
"""

    try:
        resp = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}",
            json={
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": 0,
                    "maxOutputTokens": 200
                }
            },
            timeout=2.5  # ì¹´ì¹´ì˜¤ 5ì´ˆ ì œí•œ ê³ ë ¤ (ë¶„ì„ì€ ë³„ë„ 3.5ì´ˆ)
        )

        if resp.status_code != 200:
            logger.warning(f"Gemini API ì‹¤íŒ¨: {resp.status_code}")
            return None

        result = resp.json()
        text_response = result['candidates'][0]['content']['parts'][0]['text']

        # JSON ì¶”ì¶œ (```json ... ``` ë˜ëŠ” ìˆœìˆ˜ JSON)
        json_match = re.search(r'\{[^{}]+\}', text_response)
        if not json_match:
            logger.warning(f"Gemini JSON íŒŒì‹± ì‹¤íŒ¨: {text_response}")
            return None

        parsed = json.loads(json_match.group())
        intent = parsed.get('intent', 'help')

        # intentë³„ params êµ¬ì„±
        if intent == 'date_range':
            start_str = parsed.get('start_date', today_str)
            end_str = parsed.get('end_date', today_str)
            try:
                start = datetime.strptime(start_str, '%Y-%m-%d')
                end = datetime.strptime(end_str, '%Y-%m-%d')
            except:
                start = end = today
            return ('date_range', {'start': start, 'end': end})

        elif intent == 'ingredient':
            return ('ingredient', {
                'ingredient': parsed.get('keyword', ''),
                'linked_filter': parsed.get('linked_filter'),
                'month': parsed.get('month')
            })

        elif intent == 'applicant':
            return ('applicant', {
                'applicant': parsed.get('applicant', parsed.get('keyword', '')),
                'month': parsed.get('month')
            })

        elif intent == 'country':
            return ('country', {
                'country': parsed.get('country', parsed.get('keyword', ''))
            })

        elif intent in ('weekly', 'monthly', 'summary', 'help'):
            return (intent, {})

        elif intent == 'analysis':
            return ('analysis', {
                'question': parsed.get('question', utterance)
            })

        return None

    except requests.Timeout:
        logger.warning("Gemini API íƒ€ì„ì•„ì›ƒ (3ì´ˆ)")
        return None
    except Exception as e:
        logger.warning(f"Gemini ì¸í…íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None


def run_analysis_with_gemini(question: str) -> str:
    """
    Geminiì—ê²Œ pandas ì½”ë“œë¥¼ ìƒì„±ì‹œì¼œ ë¶„ì„ ì§ˆë¬¸ì— ë‹µë³€
    Returns: ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ìš© í…ìŠ¤íŠ¸
    """
    api_key = os.environ.get("GEMINI_API_KEY", "")
    if not api_key:
        return "âš ï¸ AI ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    today = datetime.today()

    prompt = f"""ë‹¹ì‹ ì€ ì˜ì•½í’ˆ DMF ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì˜¤ëŠ˜ ë‚ ì§œ: {today.strftime('%Y-%m-%d')}

pandas DataFrame 'df'ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ëŠ” Python ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

## DataFrame ì •ë³´:
- df: ì •ìƒ(í™œì„±) DMF ë“±ë¡ ë°ì´í„°ë§Œ í¬í•¨
- ì»¬ëŸ¼:
  - ì„±ë¶„ëª… (str): ì˜ì•½í’ˆ ì„±ë¶„ëª… (ì˜ˆ: í´ë˜ë¦¬íŠ¸ë¡œë§ˆì´ì‹ , ì•„ëª©ì‹œì‹¤ë¦°ìˆ˜í™”ë¬¼)
  - ë“±ë¡ë²ˆí˜¸ (str): DMF ë“±ë¡ë²ˆí˜¸. "KR-123(1)" í˜•íƒœëŠ” í—ˆì—¬(ë³€ê²½)ê±´, "KR-123"ì€ ìµœì´ˆë“±ë¡
  - base_dmf (str): ë“±ë¡ë²ˆí˜¸ì—ì„œ ê´„í˜¸ ì œê±°í•œ ê¸°ë³¸ë²ˆí˜¸ (ê³ ìœ  ì œì¡°ì› ì‹ë³„ìš©)
  - ì‹ ì²­ì¸ (str): ìˆ˜ì…/ë“±ë¡ ì‹ ì²­ íšŒì‚¬ (ì˜ˆ: (ì£¼)íŒŒë§ˆí”¼ì•„, (ì£¼)ì„±ì§„ì—‘ì‹¬)
  - ì œì¡°ì†Œëª… (str): í•´ì™¸ ì œì¡°ì†Œ ì´ë¦„ (ì˜ˆ: Synthimed Labs, Zhejiang Better Pharma)
  - ì œì¡°êµ­ê°€ (str): ì œì¡°ì†Œ êµ­ê°€ (ì˜ˆ: ì¸ë„, ì¤‘êµ­). ë³µìˆ˜ êµ­ê°€ëŠ” '@'ë¡œ êµ¬ë¶„
  - ìµœì´ˆë“±ë¡ì¼ì (str): ë“±ë¡ì¼ (YYYY-MM-DD í˜•ì‹)
  - has_ì—°ê³„ì‹¬ì‚¬ (bool): ì—°ê³„ì‹¬ì‚¬ ì—¬ë¶€ (True=ì—°ê³„ì‹¬ì‚¬ ìˆìŒ)
  - is_í—ˆì—¬ (bool): í—ˆì—¬(ë³€ê²½)ê±´ ì—¬ë¶€ (True=í—ˆì—¬ê±´, False=ìµœì´ˆë“±ë¡)

## í•µì‹¬ ê°œë…:
- "ì œì¡°ì›ìˆ˜" = base_dmfì˜ ê³ ìœ  ê°œìˆ˜ (nunique). ê°™ì€ ì œì¡°ì›ì˜ í—ˆì—¬ê±´ì€ ê°™ì€ base_dmfë¥¼ ê³µìœ 
- "ì„±ë¶„" = ì„±ë¶„ëª… ì»¬ëŸ¼
- "ì—°ê³„ì‹¬ì‚¬" = has_ì—°ê³„ì‹¬ì‚¬ê°€ Trueì¸ ê²ƒ
- ì œì¡°êµ­ê°€ì—ì„œ ì£¼ìš” êµ­ê°€ ì¶”ì¶œ: .str.split('@').str[0] ë˜ëŠ” .str.contains()

## ê·œì¹™:
1. ê²°ê³¼ë¥¼ result ë³€ìˆ˜ì— ë¬¸ìì—´ë¡œ ì €ì¥í•˜ì„¸ìš”
2. ê²°ê³¼ëŠ” ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ìš©ì´ë¯€ë¡œ ê°„ê²°í•˜ê²Œ (ìµœëŒ€ 800ì)
3. ëª©ë¡ì€ ìµœëŒ€ 15ê°œê¹Œì§€ë§Œ í‘œì‹œí•˜ê³  ë‚˜ë¨¸ì§€ëŠ” "ì™¸ Nê°œ"ë¡œ
4. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš© (ğŸ“ŠğŸ’ŠğŸ­ ë“±)
5. importë¬¸ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€! df, pd, Counter, datetime, timedeltaëŠ” ì´ë¯¸ ì‚¬ìš© ê°€ëŠ¥
6. í•¨ìˆ˜ë¡œ ê°ì‹¸ì§€ ë§ê³  ë°”ë¡œ ì½”ë“œë§Œ ì‘ì„± (def ì‚¬ìš© ê¸ˆì§€)
7. ì½”ë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ```python ë§ˆí¬ë‹¤ìš´ ì—†ì´
8. íŠ¹ì • íšŒì‚¬/ì„±ë¶„/êµ­ê°€ê°€ ì–¸ê¸‰ë˜ë©´ ë°˜ë“œì‹œ í•´ë‹¹ ì¡°ê±´ìœ¼ë¡œ dfë¥¼ í•„í„°ë§í•œ í›„ ë¶„ì„í•˜ì„¸ìš”
   ì˜ˆ: "íœ´ì‹œë“œ ë¶„ì„" â†’ df[df['ì‹ ì²­ì¸'].str.contains('íœ´ì‹œë“œ')]ë¡œ í•„í„° í›„ ë¶„ì„
   ì˜ˆ: "ì¸ë„ ì œì¡°ì†Œ ë¶„ì„" â†’ df[df['ì œì¡°êµ­ê°€'].str.contains('ì¸ë„')]ë¡œ í•„í„° í›„ ë¶„ì„

ì‚¬ìš©ì ì§ˆë¬¸: "{question}"
"""

    try:
        # Geminiì—ê²Œ pandas ì½”ë“œ ìƒì„± ìš”ì²­
        resp = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}",
            json={
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": 0,
                    "maxOutputTokens": 1000
                }
            },
            timeout=4
        )

        if resp.status_code != 200:
            logger.warning(f"Gemini ë¶„ì„ API ì‹¤íŒ¨: {resp.status_code}")
            return "âš ï¸ AI ë¶„ì„ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        result_json = resp.json()
        code_text = result_json['candidates'][0]['content']['parts'][0]['text']

        # ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ (```python ... ``` ì œê±°)
        code_text = re.sub(r'```python\s*', '', code_text)
        code_text = re.sub(r'```\s*', '', code_text)
        code_text = code_text.strip()

        # ì•ˆì „ ì²˜ë¦¬: importë¬¸ ì œê±°, print ë¬´ì‹œ
        code_lines = []
        for line in code_text.split('\n'):
            stripped = line.strip()
            if stripped.startswith('import ') or stripped.startswith('from '):
                continue  # import ì œê±°
            code_lines.append(line)
        code_text = '\n'.join(code_lines)

        logger.info(f"ğŸ§ª Gemini ìƒì„± ì½”ë“œ:\n{code_text}")

        # ì•ˆì „í•œ ì‹¤í–‰ í™˜ê²½
        active = _get_cached_data()
        df = active.copy()

        # ì‹¤í–‰ í™˜ê²½ (Gemini ìƒì„± ì½”ë“œ ì „ìš© â€” ì‚¬ìš©ì ì§ì ‘ ì…ë ¥ ì•„ë‹˜)
        import builtins as _builtins
        exec_env = {'__builtins__': _builtins}
        exec_env['df'] = df
        exec_env['pd'] = pd
        exec_env['Counter'] = Counter
        exec_env['datetime'] = datetime
        exec_env['timedelta'] = timedelta
        exec_env['result'] = 'ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'

        try:
            exec(code_text, exec_env)
            result = exec_env.get('result', 'ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
        except Exception as exec_err:
            logger.error(f"ì½”ë“œ ì‹¤í–‰ ì—ëŸ¬: {exec_err}")
            result = f"ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(exec_err)[:100]}"

        # ê²°ê³¼ ê¸¸ì´ ì œí•œ (ì¹´ì¹´ì˜¤ 1000ì)
        result = str(result)
        if len(result) > 900:
            result = result[:900] + "\n... (ê²°ê³¼ê°€ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œ)"

        return f"ğŸ“Š AI ë¶„ì„ ê²°ê³¼\n{'â”€'*24}\nâ“ {question}\n\n{result}\n\nì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼"

    except requests.Timeout:
        return "âš ï¸ ë¶„ì„ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.\në” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ì‹œë„í•´ì£¼ì„¸ìš”."
    except Exception as e:
        logger.error(f"ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\në‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.\n\nğŸ’¡ ì˜ˆ: ì œì¡°ì› 3ê°œ ì´í•˜ ì„±ë¶„, ì—°ê³„ì‹¬ì‚¬ ë¹„ìœ¨ Top 10"


def parse_user_intent(utterance: str) -> tuple:
    """
    ì‚¬ìš©ì ë°œí™”ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë„ì™€ íŒŒë¼ë¯¸í„° ì¶”ì¶œ

    Returns:
        (intent, params) íŠœí”Œ
        intent: 'weekly' | 'monthly' | 'date_range' | 'ingredient' | 'country' | 'applicant' | 'summary' | 'help'
    """
    text = utterance.strip().lower()
    today = datetime.today()

    # â”€â”€â”€ 1. ì¸ì‚¬ / ë„ì›€ë§ â”€â”€â”€
    if text in ['ì•ˆë…•', 'í•˜ì´', 'hi', 'hello', 'ì‹œì‘', ''] or len(text) <= 1:
        return ('help', {})
    if any(kw in text for kw in ['ë„ì›€', 'ì‚¬ìš©ë²•', 'ì•ˆë‚´', 'ë©”ë‰´', 'ë­˜ í•  ìˆ˜', 'ê¸°ëŠ¥', 'ëª…ë ¹', 'ë­ í• ', 'ë­˜ ë¬¼', 'ì–´ë–»ê²Œ']):
        return ('help', {})

    # â”€â”€â”€ 2. ìš”ì•½ â”€â”€â”€
    if any(kw in text for kw in ['ìš”ì•½', 'ê³µìœ ', 'ì •ë¦¬', 'ì¹´í†¡', 'ì±—']):
        return ('summary', {})

    # â”€â”€â”€ 3. ë‚ ì§œ/ê¸°ê°„ ê´€ë ¨ ê²€ìƒ‰ â”€â”€â”€
    # "Nì›” Nì¼ë¶€í„° (ì˜¤ëŠ˜/Nì›” Nì¼)ê¹Œì§€" (êµ¬ì²´ì  ë²”ìœ„ ë¨¼ì €!)
    range_match = re.search(r'(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*ë¶€í„°\s*(?:ì˜¤ëŠ˜|(\d{1,2})ì›”\s*(\d{1,2})ì¼)\s*ê¹Œì§€', text)
    if range_match:
        sm, sd = int(range_match.group(1)), int(range_match.group(2))
        start = datetime(today.year, sm, sd)
        if range_match.group(3):
            em, ed = int(range_match.group(3)), int(range_match.group(4))
            end = datetime(today.year, em, ed)
        else:
            end = today
        return ('date_range', {'start': start, 'end': end})

    # "Nì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€" (ì›” ìƒëµ)
    range_match2 = re.search(r'(\d{1,2})ì¼\s*ë¶€í„°\s*ì˜¤ëŠ˜\s*ê¹Œì§€', text)
    if range_match2:
        day = int(range_match2.group(1))
        month_ctx = re.search(r'(\d{1,2})ì›”', text)
        m = int(month_ctx.group(1)) if month_ctx else today.month
        start = datetime(today.year, m, day)
        return ('date_range', {'start': start, 'end': today})

    # "ìµœê·¼ Nì¼"
    recent_match = re.search(r'ìµœê·¼\s*(\d+)\s*ì¼', text)
    if recent_match:
        days = int(recent_match.group(1))
        return ('date_range', {'start': today - timedelta(days=days), 'end': today})

    # "ì˜¤ëŠ˜ ë“±ë¡", "ì–´ì œ í˜„í™©" (ì¼ë°˜ì  ì˜¤ëŠ˜/ì–´ì œ)
    if re.search(r'ì˜¤ëŠ˜.*(ë“±ë¡|dmf|í˜„í™©|ì‹ ê·œ)', text) or re.search(r'(ë“±ë¡|dmf|í˜„í™©|ì‹ ê·œ).*ì˜¤ëŠ˜', text):
        return ('date_range', {'start': today, 'end': today})

    if re.search(r'ì–´ì œ.*(ë“±ë¡|dmf|í˜„í™©|ì‹ ê·œ)', text) or re.search(r'(ë“±ë¡|dmf|í˜„í™©|ì‹ ê·œ).*ì–´ì œ', text):
        yesterday = today - timedelta(days=1)
        return ('date_range', {'start': yesterday, 'end': yesterday})

    # "ì´ë²ˆì£¼", "ì£¼ê°„", "ê¸ˆì£¼"
    if any(kw in text for kw in ['ì£¼ê°„', 'ì´ë²ˆì£¼', 'ì´ë²ˆ ì£¼', 'ê¸ˆì£¼', 'ì§€ë‚œì£¼', 'ì§€ë‚œ ì£¼', 'ì£¼ë³„']):
        return ('weekly', {})

    # "ì›”ê°„", "ì´ë²ˆë‹¬"
    if any(kw in text for kw in ['ì›”ê°„', 'ì´ë²ˆë‹¬', 'ì´ë²ˆ ë‹¬', 'ì „ì›”', 'ì§€ë‚œë‹¬', 'ì§€ë‚œ ë‹¬', 'ì›”ë³„']):
        return ('monthly', {})

    # â”€â”€â”€ 4. ì‹ ì²­ì¸ ê²€ìƒ‰ â”€â”€â”€
    month_match = re.search(r'(\d{1,2})ì›”', text)
    month = int(month_match.group(1)) if month_match else None

    applicant_match = re.search(r'(?:ì‹ ì²­ì¸|ìˆ˜ì…ì‚¬|ìˆ˜ì…ì—…ì²´|ê±°ë˜ì²˜)\s*[:]?\s*(.+?)(?:\s*(?:í˜„í™©|ê²€ìƒ‰|ì¡°íšŒ|dmf|ë“±ë¡|ëª‡ê°œ|ê°¯ìˆ˜).*$|\s*\??\s*$)', text)
    if applicant_match:
        name = applicant_match.group(1).strip()
        if name:
            return ('applicant', {'applicant': name, 'month': month})

    # â”€â”€â”€ 5. êµ­ê°€ ê²€ìƒ‰ â”€â”€â”€
    country_keywords = ['ì¸ë„', 'ì¤‘êµ­', 'ì¼ë³¸', 'ë¯¸êµ­', 'ë…ì¼', 'ì´íƒˆë¦¬ì•„', 'ìŠ¤í˜ì¸',
                        'í”„ë‘ìŠ¤', 'ì˜êµ­', 'ìºë‚˜ë‹¤', 'ë¸Œë¼ì§ˆ', 'ëŒ€ë§Œ', 'í•œêµ­', 'ì´ìŠ¤ë¼ì—˜']
    for kw in country_keywords:
        if kw in text:
            return ('country', {'country': kw})

    # â”€â”€â”€ 6. ì„±ë¶„/í†µí•© ê²€ìƒ‰ â”€â”€â”€
    linked_filter = None
    if any(kw in text for kw in ['ì—°ê³„ ì•ˆ', 'ë¯¸ì—°ê³„', 'ì—°ê³„ì•ˆ', 'ë¹„ì—°ê³„', 'ì—°ê³„ ì—†']):
        linked_filter = 'unlinked'
    elif any(kw in text for kw in ['ì—°ê³„ì‹¬ì‚¬', 'ì—°ê³„', 'linked']):
        linked_filter = 'linked'

    # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ (ëª¨ë“  ë¶ˆí•„ìš” ë‹¨ì–´ ì œê±°)
    clean_text = re.sub(
        r'(?:ì—°ê³„ì‹¬ì‚¬|ë¯¸ì—°ê³„|ë¹„ì—°ê³„|ì—°ê³„|ì œì¡°ì›|ì œì¡°ì‚¬|í˜„í™©|ê²€ìƒ‰|ì¡°íšŒ|dmf|ë“±ë¡|í—ˆì—¬|ì‹ ê·œ|'
        r'ëœ|ì•ˆëœ|ìˆëŠ”|ì—†ëŠ”|ëª‡ê°œ|ê°¯ìˆ˜|ìˆ˜|ì•Œë ¤ì¤˜|ë³´ì—¬ì¤˜|ë­ì•¼|ì¢€|í•´ì¤˜|'
        r'ë¶€í„°|ê¹Œì§€|ì˜¤ëŠ˜|ì–´ì œ|ìµœê·¼|ê¸°ê°„|ì¤‘ì—ì„œ|ì¤‘|ì—ì„œ|ì˜|ì—)',
        ' ', text
    ).strip()
    clean_text = re.sub(r'\d{1,2}ì›”\s*(?:\d{1,2}ì¼)?\s*(?:ì—|ì˜|ì€|ëŠ”)?\s*', '', clean_text).strip()
    clean_text = re.sub(r'\d{1,2}ì¼', '', clean_text).strip()
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    clean_text = re.sub(r'[?ï¼Ÿ!]$', '', clean_text).strip()
    clean_text = re.sub(r'(?:ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼)$', '', clean_text).strip()

    if clean_text and clean_text not in ['ì•ˆë…•', 'í•˜ì´', 'hi', 'hello', 'ì‹œì‘'] and len(clean_text) > 1:
        return ('ingredient', {'ingredient': clean_text, 'linked_filter': linked_filter, 'month': month})

    # â”€â”€â”€ 7. ìœ„ ëª¨ë“  ê²ƒì— í•´ë‹¹ ì•ˆ ë˜ë©´ â”€â”€â”€
    # ë‚ ì§œ ê´€ë ¨ ë‹¨ì–´ë§Œ ìˆì—ˆìœ¼ë©´ â†’ ì£¼ê°„ í˜„í™©ìœ¼ë¡œ
    if any(kw in text for kw in ['ë“±ë¡', 'í˜„í™©', 'dmf', 'ì‹ ê·œ']):
        return ('weekly', {})

    return ('help', {})


# â”€â”€â”€ ì¹´ì¹´ì˜¤ ì›¹í›… ì—”ë“œí¬ì¸íŠ¸ë“¤ â”€â”€â”€

@app.get("/")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "service": "DMF Intelligence Server",
        "cache": "loaded" if _cache["df"] is not None else "empty",
        "last_updated": str(_cache["last_updated"]) if _cache["last_updated"] else None,
        "endpoints": {
            "kakao_webhook": "/kakao/skill",
            "mcp_sse": "/sse" if MCP_AVAILABLE else "not available"
        }
    }


@app.get("/refresh")
async def refresh_cache():
    """ìºì‹œ ê°•ì œ ê°±ì‹  (Cron Jobìš©) â€” ë§¤ì¼ ì•„ì¹¨ 7ì‹œ í˜¸ì¶œ"""
    try:
        _cache["df"] = None
        _cache["last_updated"] = None
        _get_cached_data()
        return {
            "status": "refreshed",
            "records": len(_cache["df"]),
            "updated_at": str(_cache["last_updated"])
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.post("/kakao/skill")
async def kakao_skill_handler(request: Request):
    """
    ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë” í†µí•© Skill ì—”ë“œí¬ì¸íŠ¸
    
    ì‚¬ìš©ì ë°œí™”ë¥¼ ìë™ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ DMF ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì˜¤í”ˆë¹Œë”ì˜ 'í´ë°± ë¸”ë¡'ì— ì—°ê²°í•˜ë©´, ëª¨ë“  ì…ë ¥ì„ ì—¬ê¸°ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    AI ì±—ë´‡ ëª¨ë“œ: callbackUrlì´ ìˆìœ¼ë©´ ë¶„ì„ ì§ˆë¬¸ì€ ë¹„ë™ê¸° ì½œë°±ìœ¼ë¡œ ì²˜ë¦¬
    """
    try:
        body = await request.json()
        utterance = body.get("userRequest", {}).get("utterance", "")
        params = body.get("action", {}).get("params", {})
        callback_url = body.get("userRequest", {}).get("callbackUrl", "")

        logger.info(f"ğŸ“¨ ì¹´ì¹´ì˜¤ ìš”ì²­: '{utterance}' | callback: {'ìˆìŒ' if callback_url else 'ì—†ìŒ'}")

        # ìºì‹œê°€ ì•„ì§ ì¤€ë¹„ ì•ˆ ëìœ¼ë©´ ì¦‰ì‹œ ì•ˆë‚´
        if _cache["df"] is None and _cache["loading"]:
            return JSONResponse(kakao_simple_text(
                "ğŸ”„ ì„œë²„ê°€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.\n10ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!"
            ))

        intent, extracted = parse_user_intent(utterance)

        # Gemini AI ì¸í…íŠ¸ ë¶„ì„ ì‹œë„ â†’ ì‹¤íŒ¨ ì‹œ regex ê²°ê³¼ ì‚¬ìš©
        gemini_result = parse_intent_with_gemini(utterance)
        if gemini_result:
            intent, extracted = gemini_result
            logger.info(f"ğŸ¤– Gemini: intent={intent}, params={extracted}")
        else:
            logger.info(f"ğŸ“ Regex: intent={intent}, params={extracted}")

        # â”€â”€ analysis ì¸í…íŠ¸: ì½œë°±ìœ¼ë¡œ ë¹„ë™ê¸° ì²˜ë¦¬ â”€â”€
        if intent == 'analysis':
            question = extracted.get('question', utterance)

            if callback_url:
                # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹¤í–‰ â†’ ì½œë°±ìœ¼ë¡œ ì „ì†¡
                def run_and_callback():
                    try:
                        result_text = run_analysis_with_gemini(question)
                        callback_body = {
                            "version": "2.0",
                            "template": {
                                "outputs": [{"simpleText": {"text": result_text}}],
                                "quickReplies": [
                                    {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                                    {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                                ]
                            }
                        }
                        cb_resp = requests.post(callback_url, json=callback_body, timeout=5)
                        logger.info(f"ğŸ“¤ ì½œë°± ì „ì†¡ ì™„ë£Œ: {cb_resp.status_code}")
                    except Exception as e:
                        logger.error(f"âŒ ì½œë°± ì‹¤íŒ¨: {e}")

                threading.Thread(target=run_and_callback, daemon=True).start()

                # ì¦‰ì‹œ "ë¶„ì„ ì¤‘" ì‘ë‹µ (5ì´ˆ ì•ˆì— ë°˜í™˜)
                return JSONResponse({
                    "version": "2.0",
                    "useCallback": True,
                    "template": {
                        "outputs": [{"simpleText": {"text": "ğŸ¤– AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...\nì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!"}}]
                    }
                })
            else:
                # ì½œë°± ì—†ìœ¼ë©´ ì§ì ‘ ì²˜ë¦¬ (5ì´ˆ ì´ˆê³¼ ìœ„í—˜)
                text = run_analysis_with_gemini(question)
                return JSONResponse(kakao_quick_replies(text, [
                    {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                    {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                ]))

        elif intent == 'weekly':
            data = analyze_weekly_dmf()
            text = format_weekly_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ìš”ì•½", "action": "message", "label": "ğŸ“‹ ì±„íŒ… ê³µìœ ìš©"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ì‚¬ìš©ë²•"}
            ]))

        elif intent == 'monthly':
            data = analyze_monthly_dmf()
            text = format_monthly_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì¸ë„", "action": "message", "label": "ğŸ‡®ğŸ‡³ ì¸ë„ DMF"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ì‚¬ìš©ë²•"}
            ]))

        elif intent == 'summary':
            text = generate_chat_summary()
            return JSONResponse(kakao_simple_text(text))

        elif intent == 'date_range':
            start = extracted.get('start', datetime.today())
            end = extracted.get('end', datetime.today())
            data = search_date_range(start, end)
            text = format_date_range_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
            ]))

        elif intent == 'country':
            country = extracted.get('country', params.get('country', ''))
            if not country:
                return JSONResponse(kakao_simple_text("ì–´ëŠ êµ­ê°€ì˜ DMFë¥¼ ê²€ìƒ‰í• ê¹Œìš”?\n\nì˜ˆ: ì¸ë„, ì¤‘êµ­, ì¼ë³¸, ë¯¸êµ­"))
            data = search_country(country)
            text = format_country_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
            ]))

        elif intent == 'applicant':
            applicant = extracted.get('applicant', params.get('applicant', ''))
            month = extracted.get('month')
            if not applicant:
                return JSONResponse(kakao_simple_text("ê²€ìƒ‰í•  ì‹ ì²­ì¸ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆ: ì‹ ì²­ì¸ íœ´ì‹œë“œ\nì˜ˆ: 1ì›”ì— ì‹ ì²­ì¸ êµ­ì „ì•½í’ˆ í˜„í™©"))
            data = search_applicant(applicant, month)
            text = format_applicant_for_kakao(data)
            return JSONResponse(kakao_quick_replies(text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
            ]))

        elif intent == 'ingredient':
            keyword = extracted.get('ingredient', params.get('ingredient', ''))
            linked_filter = extracted.get('linked_filter')
            if not keyword:
                return JSONResponse(kakao_simple_text("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆ: ì„¸íŒŒí´ëŸ¬, íœ´ì‹œë“œ, ì¸ë„"))

            # ì—°ê³„ í•„í„°ê°€ ìˆìœ¼ë©´ ì„±ë¶„ëª… ê²€ìƒ‰ ê³ ì •
            if linked_filter:
                data = search_ingredient(keyword, linked_filter)
                text = format_ingredient_for_kakao(data)
                replies = []
                if linked_filter != 'linked':
                    replies.append({"messageText": f"{keyword} ì—°ê³„ì‹¬ì‚¬", "action": "message", "label": "âœ… ì—°ê³„ì‹¬ì‚¬ë§Œ"})
                if linked_filter != 'unlinked':
                    replies.append({"messageText": f"{keyword} ë¯¸ì—°ê³„", "action": "message", "label": "â¬œ ë¯¸ì—°ê³„ë§Œ"})
                replies.append({"messageText": keyword, "action": "message", "label": "ğŸ“‹ ì „ì²´ ë³´ê¸°"})
                replies.append({"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"})
                return JSONResponse(kakao_quick_replies(text, replies[:4]))

            # í†µí•© ê²€ìƒ‰: ì„±ë¶„ëª… â†’ ì‹ ì²­ì¸ â†’ ì œì¡°ì†Œëª…
            month = extracted.get('month')
            search_type, uni_data = search_universal(keyword, month)

            if search_type == 'ingredient':
                data = search_ingredient(keyword)
                text = format_ingredient_for_kakao(data)
                return JSONResponse(kakao_quick_replies(text, [
                    {"messageText": f"{keyword} ì—°ê³„ì‹¬ì‚¬", "action": "message", "label": "âœ… ì—°ê³„ì‹¬ì‚¬ë§Œ"},
                    {"messageText": f"{keyword} ë¯¸ì—°ê³„", "action": "message", "label": "â¬œ ë¯¸ì—°ê³„ë§Œ"},
                    {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                ]))

            elif search_type == 'applicant':
                text = format_applicant_for_kakao(uni_data)
                return JSONResponse(kakao_quick_replies(text, [
                    {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                    {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                    {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                ]))

            elif search_type == 'manufacturer':
                text = format_manufacturer_for_kakao(uni_data)
                return JSONResponse(kakao_quick_replies(text, [
                    {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                    {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                    {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                ]))

            else:
                return JSONResponse(kakao_quick_replies(
                    f"ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼\n\nì„±ë¶„ëª…Â·ì‹ ì²­ì¸Â·ì œì¡°ì†Œì—ì„œ\nì¼ì¹˜í•˜ëŠ” í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.",
                    [
                        {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                        {"messageText": "ë„ì›€", "action": "message", "label": "â“ ë©”ë‰´"}
                    ]
                ))

        else:  # help
            help_text = (
                "ğŸ’Š DMF Intelligence\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ DMF ë°ì´í„°ë¥¼\n"
                "ì‹¤ì‹œê°„ìœ¼ë¡œ ì¡°íšŒÂ·ë¶„ì„í•©ë‹ˆë‹¤.\n\n"
                "ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”!\n\n"
                "ğŸ’¡ ì…ë ¥ ì˜ˆì‹œ:\n"
                "â€¢ ì„¸íŒŒí´ëŸ¬ â†’ ì œì¡°ì› í˜„í™©\n"
                "â€¢ íœ´ì‹œë“œ â†’ ì‹ ì²­ì¸ ê²€ìƒ‰\n"
                "â€¢ ì¸ë„ â†’ êµ­ê°€ë³„ DMF í˜„í™©\n"
                "â€¢ 2ì›”9ì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ â†’ ê¸°ê°„\n"
                "â€¢ ìµœê·¼ 3ì¼ â†’ ìµœê·¼ ë“±ë¡ í˜„í™©\n\n"
                "ğŸ¤– AI ë¶„ì„ ì§ˆë¬¸ë„ ê°€ëŠ¥:\n"
                "â€¢ ì œì¡°ì› 3ê°œ ì´í•˜ì¸ ì„±ë¶„ì€?\n"
                "â€¢ ì—°ê³„ì‹¬ì‚¬ ë¹„ìœ¨ Top 10\n"
                "â€¢ ì˜¬í•´ ê°€ì¥ ë§ì´ ë“±ë¡í•œ ì‹ ì²­ì¸"
            )
            return JSONResponse(kakao_quick_replies(help_text, [
                {"messageText": "ì£¼ê°„", "action": "message", "label": "ğŸ“‹ ì£¼ê°„ í˜„í™©"},
                {"messageText": "ì›”ê°„", "action": "message", "label": "ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸"},
                {"messageText": "ì œì¡°ì› 3ê°œ ì´í•˜ ì„±ë¶„ì€?", "action": "message", "label": "ğŸ¤– AI ë¶„ì„"},
                {"messageText": "ì¸ë„", "action": "message", "label": "ğŸ‡®ğŸ‡³ ì¸ë„ DMF"}
            ]))

    except Exception as e:
        logger.error(f"âŒ ì¹´ì¹´ì˜¤ ìŠ¤í‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return JSONResponse(kakao_simple_text(
            f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\n(ì˜¤ë¥˜: {str(e)[:100]})"
        ))


# ê°œë³„ ìŠ¤í‚¬ ì—”ë“œí¬ì¸íŠ¸ (ì˜¤í”ˆë¹Œë”ì—ì„œ ë¸”ë¡ë³„ë¡œ ì—°ê²°í•  ë•Œ ì‚¬ìš©)
@app.post("/kakao/weekly")
async def kakao_weekly(request: Request):
    """ì£¼ê°„ DMF í˜„í™© ì „ìš© ìŠ¤í‚¬"""
    try:
        data = analyze_weekly_dmf()
        text = format_weekly_for_kakao(data)
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:100]}"))


@app.post("/kakao/monthly")
async def kakao_monthly(request: Request):
    """ì›”ê°„ DMF ë¦¬í¬íŠ¸ ì „ìš© ìŠ¤í‚¬"""
    try:
        data = analyze_monthly_dmf()
        text = format_monthly_for_kakao(data)
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:100]}"))


@app.post("/kakao/summary")
async def kakao_summary(request: Request):
    """ì±„íŒ… ê³µìœ ìš© ìš”ì•½ ì „ìš© ìŠ¤í‚¬"""
    try:
        text = generate_chat_summary()
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ìš”ì•½ ì‹¤íŒ¨: {str(e)[:100]}"))


@app.post("/kakao/ingredient")
async def kakao_ingredient(request: Request):
    """ì„±ë¶„ëª… ê²€ìƒ‰ ì „ìš© ìŠ¤í‚¬ (íŒŒë¼ë¯¸í„°: ingredient)"""
    try:
        body = await request.json()
        utterance = body.get("userRequest", {}).get("utterance", "")
        ingredient = body.get("action", {}).get("params", {}).get("ingredient", utterance)

        if not ingredient:
            return JSONResponse(kakao_simple_text("ê²€ìƒ‰í•  ì„±ë¶„ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."))

        data = search_ingredient(ingredient)
        text = format_ingredient_for_kakao(data)
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)[:100]}"))


@app.post("/kakao/country")
async def kakao_country(request: Request):
    """êµ­ê°€ ê²€ìƒ‰ ì „ìš© ìŠ¤í‚¬ (íŒŒë¼ë¯¸í„°: country)"""
    try:
        body = await request.json()
        utterance = body.get("userRequest", {}).get("utterance", "")
        country = body.get("action", {}).get("params", {}).get("country", utterance)

        if not country:
            return JSONResponse(kakao_simple_text("ê²€ìƒ‰í•  êµ­ê°€ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."))

        data = search_country(country)
        text = format_country_for_kakao(data)
        return JSONResponse(kakao_simple_text(text))
    except Exception as e:
        return JSONResponse(kakao_simple_text(f"âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)[:100]}"))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„œë²„ ì‹¤í–‰ (MCP + ì¹´ì¹´ì˜¤ ë™ì‹œ ì§€ì›)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    mode = os.environ.get("SERVER_MODE", "kakao")  # "kakao" | "mcp" | "both"

    if mode == "mcp" and MCP_AVAILABLE:
        # MCP ì „ìš© ëª¨ë“œ (Claude Desktop / PlayMCP)
        print(f"ğŸš€ DMF MCP Server (SSE) ì‹œì‘ â€” Port {port}")
        mcp.run(transport="sse", port=port)

    elif mode == "both" and MCP_AVAILABLE:
        # ë‘ ì„œë²„ ë™ì‹œ ì‹¤í–‰ (ë³„ë„ í¬íŠ¸)
        import threading
        mcp_port = int(os.environ.get("MCP_PORT", 8001))

        def run_mcp():
            print(f"ğŸš€ MCP Server ì‹œì‘ â€” Port {mcp_port}")
            mcp.run(transport="sse", port=mcp_port)

        mcp_thread = threading.Thread(target=run_mcp, daemon=True)
        mcp_thread.start()

        print(f"ğŸš€ ì¹´ì¹´ì˜¤ ì›¹í›… Server ì‹œì‘ â€” Port {port}")
        uvicorn.run(app, host="0.0.0.0", port=port)

    else:
        # ì¹´ì¹´ì˜¤ ì›¹í›… ì „ìš© ëª¨ë“œ (ê¸°ë³¸)
        print(f"ğŸš€ DMF ì¹´ì¹´ì˜¤ ì±—ë´‡ Server ì‹œì‘ â€” Port {port}")
        print(f"   ì›¹í›… URL: https://YOUR-APP.onrender.com/kakao/skill")
        uvicorn.run(app, host="0.0.0.0", port=port)
