"""
DMF Intelligence MCP Server
============================
ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ DMF ë°ì´í„°ë¥¼ ì¡°íšŒÂ·ë¶„ì„í•˜ëŠ” MCP ì„œë²„
PlayMCP ë° Claude/ChatGPTì—ì„œ ì‚¬ìš© ê°€ëŠ¥

ì‚¬ìš© ì˜ˆì‹œ (AI ëŒ€í™”):
  "ì´ë²ˆ ì£¼ ì‹ ê·œ DMF ë“±ë¡ í˜„í™© ì•Œë ¤ì¤˜"
  "ì¸ë„ ì œì¡°ì‚¬ DMFë§Œ ë³´ì—¬ì¤˜"
  "ìµœê·¼ í•œ ë‹¬ DMF íŠ¸ë Œë“œ ë¶„ì„í•´ì¤˜"
"""

import os
import json
import tempfile
import logging
from datetime import datetime, timedelta
from collections import Counter
from typing import Optional

import requests
import pandas as pd
from mcp.server.fastmcp import FastMCP

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MCP ì„œë²„ ì´ˆê¸°í™”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

mcp = FastMCP(
    "dmf-intelligence",
    instructions="""DMF(Drug Master File) ë“±ë¡ í˜„í™©ì„ ì¡°íšŒÂ·ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
    ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼(nedrug.mfds.go.kr)ì˜ ê³µê°œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ì‹ ê·œ DMF ë“±ë¡, êµ­ê°€ë³„/ì„±ë¶„ë³„ ë¶„ì„, ê²½ìŸ ë™í–¥ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤.
    í•œêµ­ ì œì•½ ì›ë£Œ(API) ì‹œì¥ì˜ ì†Œì‹± ì¸í…”ë¦¬ì „ìŠ¤ì— í™œìš©ë©ë‹ˆë‹¤."""
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("dmf-mcp")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë‚´ë¶€ í•¨ìˆ˜: ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _download_dmf_excel() -> str:
    """ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ì—ì„œ DMF ì—‘ì…€ ë‹¤ìš´ë¡œë“œ â†’ ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    url = "https://nedrug.mfds.go.kr/pbp/CCBAC03/getExcel"
    logger.info("ğŸ“¥ DMF ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    response = requests.get(url, timeout=120)
    response.raise_for_status()

    tmp = tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False)
    tmp.write(response.content)
    tmp.close()
    logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {tmp.name}")
    return tmp.name


def _load_and_prepare(excel_path: str) -> pd.DataFrame:
    """ì—‘ì…€ ë¡œë“œ + ê¸°ë³¸ ì „ì²˜ë¦¬"""
    df = pd.read_excel(excel_path)
    df['ìµœì´ˆë“±ë¡ì¼ì'] = pd.to_datetime(df['ìµœì´ˆë“±ë¡ì¼ì'], errors='coerce')

    # ë“±ë¡ìœ í˜• ë¶„ë¥˜
    df['is_í—ˆì—¬'] = df['ë“±ë¡ë²ˆí˜¸'].astype(str).str.contains(r'\(', na=False)
    df['ë“±ë¡ìœ í˜•'] = df['is_í—ˆì—¬'].map({True: 'í—ˆì—¬(ë³€ê²½)', False: 'ìµœì´ˆë“±ë¡'})

    # ì—°ê³„ì‹¬ì‚¬ ì—¬ë¶€
    df['base_dmf'] = df['ë“±ë¡ë²ˆí˜¸'].astype(str).apply(
        lambda x: x.split('(', 1)[0] if '(' in x else x
    )
    has_linked = df['ì—°ê³„ì‹¬ì‚¬ë¬¸ì„œë²ˆí˜¸'].notna() & (df['ì—°ê³„ì‹¬ì‚¬ë¬¸ì„œë²ˆí˜¸'].astype(str).str.strip() != '')
    linked_bases = set(df.loc[has_linked, 'base_dmf'])
    df['has_ì—°ê³„ì‹¬ì‚¬'] = df['base_dmf'].isin(linked_bases)

    # ì •ìƒ ìƒíƒœë§Œ
    active = df[df['ì·¨ì†Œ/ì·¨í•˜êµ¬ë¶„'] == 'ì •ìƒ'].copy()
    return active


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MCP Tools (AIê°€ í˜¸ì¶œí•˜ëŠ” ë„êµ¬ë“¤)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@mcp.tool()
def get_weekly_dmf(weeks_ago: int = 1) -> str:
    """
    ìµœê·¼ ì£¼ê°„ DMF ë“±ë¡ í˜„í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        weeks_ago: ëª‡ ì£¼ ì „ ë°ì´í„°ë¥¼ ì¡°íšŒí• ì§€ (ê¸°ë³¸ê°’ 1 = ì§€ë‚œì£¼)

    Returns:
        ì£¼ê°„ DMF ë“±ë¡ ìš”ì•½ (ê±´ìˆ˜, ìµœì´ˆ/í—ˆì—¬, ì„±ë¶„ë³„ ìƒì„¸)
    """
    try:
        excel_path = _download_dmf_excel()
        active = _load_and_prepare(excel_path)

        today = datetime.today()
        days_since_monday = today.weekday()
        this_monday = today - timedelta(days=days_since_monday)
        target_monday = this_monday - timedelta(weeks=weeks_ago)
        target_friday = target_monday + timedelta(days=4)

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(target_monday)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(target_friday))
        week_df = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        week_label = f"{target_monday.strftime('%m/%d')}~{target_friday.strftime('%m/%d')}"

        if len(week_df) == 0:
            return json.dumps({
                "ê¸°ê°„": week_label,
                "ë©”ì‹œì§€": "í•´ë‹¹ ì£¼ê°„ ì‹ ê·œ DMF ë“±ë¡ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤."
            }, ensure_ascii=False)

        # ìƒì„¸ ë‚´ì—­
        details = []
        for _, row in week_df.iterrows():
            details.append({
                "ë“±ë¡ì¼": row['ìµœì´ˆë“±ë¡ì¼ì'].strftime('%m/%d'),
                "ë“±ë¡ìœ í˜•": 'í—ˆì—¬' if row['is_í—ˆì—¬'] else 'ìµœì´ˆ',
                "ì„±ë¶„ëª…": str(row.get('ì„±ë¶„ëª…', '')),
                "ì‹ ì²­ì¸": str(row.get('ì‹ ì²­ì¸', '')),
                "ì œì¡°ì†Œ": str(row.get('ì œì¡°ì†Œëª…', ''))[:25],
                "êµ­ê°€": str(row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/'),
                "ì—°ê³„ì‹¬ì‚¬": 'O' if row['has_ì—°ê³„ì‹¬ì‚¬'] else 'X'
            })

        result = {
            "ê¸°ê°„": week_label,
            "ì´ê±´ìˆ˜": len(week_df),
            "ìµœì´ˆë“±ë¡": int((~week_df['is_í—ˆì—¬']).sum()),
            "í—ˆì—¬_ë³€ê²½": int(week_df['is_í—ˆì—¬'].sum()),
            "ì—°ê³„ì‹¬ì‚¬_ìˆìŒ": int(week_df['has_ì—°ê³„ì‹¬ì‚¬'].sum()),
            "ìƒì„¸ë‚´ì—­": details
        }

        os.unlink(excel_path)
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"ì£¼ê°„ DMF ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return json.dumps({"error": str(e)}, ensure_ascii=False)


@mcp.tool()
def get_monthly_dmf_summary(months_ago: int = 1) -> str:
    """
    ì›”ê°„ DMF ë“±ë¡ í˜„í™© ìš”ì•½ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    ì „ì›” ëŒ€ë¹„ ë³€ë™ë¥ , êµ­ê°€ë³„ ë¶„í¬, ì£¼ìš” ì‹ ì²­ì¸, ê²½ìŸ ì„±ë¶„ì„ ë¶„ì„í•©ë‹ˆë‹¤.

    Args:
        months_ago: ëª‡ ê°œì›” ì „ ë°ì´í„°ë¥¼ ì¡°íšŒí• ì§€ (ê¸°ë³¸ê°’ 1 = ì „ì›”)

    Returns:
        ì›”ê°„ DMF ë¶„ì„ ìš”ì•½
    """
    try:
        excel_path = _download_dmf_excel()
        active = _load_and_prepare(excel_path)

        today = datetime.today()
        # ëŒ€ìƒ ì›” ê³„ì‚°
        target_end = today.replace(day=1) - timedelta(days=1)
        for _ in range(months_ago - 1):
            target_end = target_end.replace(day=1) - timedelta(days=1)
        target_start = target_end.replace(day=1)

        month_label = target_start.strftime('%Yë…„ %mì›”')

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(target_start)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(target_end))
        month_df = active[mask]

        # ì „ì „ì›” (ë¹„êµìš©)
        prev_end = target_start - timedelta(days=1)
        prev_start = prev_end.replace(day=1)
        prev_mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(prev_start)) & \
                    (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(prev_end))
        prev_count = int(active[prev_mask].shape[0])

        # ë³€ë™ë¥ 
        if prev_count > 0:
            change_pct = (len(month_df) - prev_count) / prev_count * 100
            change_str = f"+{change_pct:.1f}%" if change_pct >= 0 else f"{change_pct:.1f}%"
        else:
            change_str = "N/A"

        # êµ­ê°€ë³„
        countries = []
        for c in month_df['ì œì¡°êµ­ê°€'].dropna():
            for cc in str(c).split('@'):
                countries.append(cc.strip())
        country_counts = Counter(countries).most_common(10)
        total_c = sum(dict(country_counts).values())
        country_list = [
            {"êµ­ê°€": c, "ê±´ìˆ˜": n, "ë¹„ìœ¨": f"{n/total_c*100:.1f}%"}
            for c, n in country_counts
        ]

        # ì£¼ìš” ì‹ ì²­ì¸
        top_applicants = month_df.groupby('ì‹ ì²­ì¸').agg(
            ê±´ìˆ˜=('ë“±ë¡ë²ˆí˜¸', 'count')
        ).sort_values('ê±´ìˆ˜', ascending=False).head(5)
        applicant_list = [
            {"ì‹ ì²­ì¸": name, "ê±´ìˆ˜": int(row['ê±´ìˆ˜'])}
            for name, row in top_applicants.iterrows()
        ]

        # ê²½ìŸ ì„±ë¶„ (ë™ì¼ ì„±ë¶„ ë‹¤ìˆ˜ ì‹ ì²­ì¸)
        competition = month_df.groupby('ì„±ë¶„ëª…').agg(
            ì‹ ì²­ì¸ìˆ˜=('ì‹ ì²­ì¸', 'nunique'),
            ì‹ ì²­ì¸ëª©ë¡=('ì‹ ì²­ì¸', lambda x: ', '.join(x.unique())),
        ).query('ì‹ ì²­ì¸ìˆ˜ >= 2').sort_values('ì‹ ì²­ì¸ìˆ˜', ascending=False)
        competition_list = [
            {"ì„±ë¶„ëª…": name, "ì‹ ì²­ì¸ìˆ˜": int(row['ì‹ ì²­ì¸ìˆ˜']), "ì‹ ì²­ì¸": row['ì‹ ì²­ì¸ëª©ë¡']}
            for name, row in competition.head(10).iterrows()
        ]

        result = {
            "ê¸°ê°„": month_label,
            "ì´ê±´ìˆ˜": len(month_df),
            "ìµœì´ˆë“±ë¡": int((~month_df['is_í—ˆì—¬']).sum()),
            "í—ˆì—¬_ë³€ê²½": int(month_df['is_í—ˆì—¬'].sum()),
            "ì „ì›”ëŒ€ë¹„_ë³€ë™": change_str,
            "ì „ì›”_ê±´ìˆ˜": prev_count,
            "êµ­ê°€ë³„_ë¶„í¬": country_list,
            "ì£¼ìš”_ì‹ ì²­ì¸_TOP5": applicant_list,
            "ê²½ìŸ_ì„±ë¶„": competition_list
        }

        os.unlink(excel_path)
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"ì›”ê°„ DMF ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return json.dumps({"error": str(e)}, ensure_ascii=False)


@mcp.tool()
def search_dmf_by_ingredient(ingredient: str) -> str:
    """
    íŠ¹ì • ì„±ë¶„ëª…ìœ¼ë¡œ DMF ë“±ë¡ í˜„í™©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        ingredient: ê²€ìƒ‰í•  ì„±ë¶„ëª… (ë¶€ë¶„ ì¼ì¹˜, ì˜ˆ: "amoxicillin", "ì†Œë¼í˜ë‹™")

    Returns:
        í•´ë‹¹ ì„±ë¶„ì˜ ì „ì²´ DMF ë“±ë¡ ì´ë ¥
    """
    try:
        excel_path = _download_dmf_excel()
        active = _load_and_prepare(excel_path)

        mask = active['ì„±ë¶„ëª…'].astype(str).str.contains(ingredient, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return json.dumps({
                "ê²€ìƒ‰ì–´": ingredient,
                "ë©”ì‹œì§€": f"'{ingredient}' ê´€ë ¨ DMF ë“±ë¡ ë‚´ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }, ensure_ascii=False)

        entries = []
        for _, row in found.iterrows():
            entries.append({
                "ë“±ë¡ë²ˆí˜¸": str(row.get('ë“±ë¡ë²ˆí˜¸', '')),
                "ë“±ë¡ì¼": row['ìµœì´ˆë“±ë¡ì¼ì'].strftime('%Y-%m-%d') if pd.notna(row['ìµœì´ˆë“±ë¡ì¼ì']) else '',
                "ë“±ë¡ìœ í˜•": row['ë“±ë¡ìœ í˜•'],
                "ì„±ë¶„ëª…": str(row.get('ì„±ë¶„ëª…', '')),
                "ì‹ ì²­ì¸": str(row.get('ì‹ ì²­ì¸', '')),
                "ì œì¡°ì†Œ": str(row.get('ì œì¡°ì†Œëª…', '')),
                "êµ­ê°€": str(row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/'),
                "ì—°ê³„ì‹¬ì‚¬": 'O' if row['has_ì—°ê³„ì‹¬ì‚¬'] else 'X',
                "ìƒíƒœ": str(row.get('ì·¨ì†Œ/ì·¨í•˜êµ¬ë¶„', ''))
            })

        result = {
            "ê²€ìƒ‰ì–´": ingredient,
            "ì´_ë“±ë¡ê±´ìˆ˜": len(found),
            "ì‹ ì²­ì¸_ìˆ˜": int(found['ì‹ ì²­ì¸'].nunique()),
            "ì œì¡°êµ­ê°€_ìˆ˜": len(set(
                c.strip() for cs in found['ì œì¡°êµ­ê°€'].dropna()
                for c in str(cs).split('@')
            )),
            "ë“±ë¡ë‚´ì—­": entries[:30]  # ìµœëŒ€ 30ê±´
        }

        os.unlink(excel_path)
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"ì„±ë¶„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return json.dumps({"error": str(e)}, ensure_ascii=False)


@mcp.tool()
def search_dmf_by_country(country: str) -> str:
    """
    íŠ¹ì • êµ­ê°€ì˜ DMF ë“±ë¡ í˜„í™©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        country: ê²€ìƒ‰í•  êµ­ê°€ëª… (ë¶€ë¶„ ì¼ì¹˜, ì˜ˆ: "ì¸ë„", "ì¤‘êµ­", "India")

    Returns:
        í•´ë‹¹ êµ­ê°€ ì œì¡°ì‚¬ì˜ DMF ë“±ë¡ í˜„í™© ìš”ì•½
    """
    try:
        excel_path = _download_dmf_excel()
        active = _load_and_prepare(excel_path)

        mask = active['ì œì¡°êµ­ê°€'].astype(str).str.contains(country, case=False, na=False)
        found = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        if len(found) == 0:
            return json.dumps({
                "ê²€ìƒ‰_êµ­ê°€": country,
                "ë©”ì‹œì§€": f"'{country}' ê´€ë ¨ DMF ë“±ë¡ ë‚´ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }, ensure_ascii=False)

        # ìµœê·¼ 3ê°œì›” ì‹ ê·œ
        three_months_ago = datetime.today() - timedelta(days=90)
        recent = found[found['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(three_months_ago)]

        # ì£¼ìš” ì„±ë¶„
        top_ingredients = found['ì„±ë¶„ëª…'].value_counts().head(10)
        ingredient_list = [
            {"ì„±ë¶„ëª…": name, "ê±´ìˆ˜": int(cnt)}
            for name, cnt in top_ingredients.items()
        ]

        # ì£¼ìš” ì œì¡°ì†Œ
        top_mfrs = found['ì œì¡°ì†Œëª…'].value_counts().head(10)
        mfr_list = [
            {"ì œì¡°ì†Œ": name, "ê±´ìˆ˜": int(cnt)}
            for name, cnt in top_mfrs.items()
        ]

        result = {
            "ê²€ìƒ‰_êµ­ê°€": country,
            "ì „ì²´_ë“±ë¡ê±´ìˆ˜": len(found),
            "ìµœê·¼3ê°œì›”_ì‹ ê·œ": len(recent),
            "ì£¼ìš”_ì„±ë¶„_TOP10": ingredient_list,
            "ì£¼ìš”_ì œì¡°ì†Œ_TOP10": mfr_list
        }

        os.unlink(excel_path)
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"êµ­ê°€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return json.dumps({"error": str(e)}, ensure_ascii=False)


@mcp.tool()
def get_dmf_chat_summary() -> str:
    """
    ì¹´ì¹´ì˜¤í†¡/ë©”ì‹ ì €ì— ë°”ë¡œ ê³µìœ í•  ìˆ˜ ìˆëŠ” ê°„ê²°í•œ DMF ìš”ì•½ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì „ì£¼ ì‹ ê·œ ë“±ë¡ DMFë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        ë³µì‚¬í•´ì„œ ì±„íŒ…ë°©ì— ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥í•œ ìš”ì•½ ë©”ì‹œì§€
    """
    try:
        excel_path = _download_dmf_excel()
        active = _load_and_prepare(excel_path)

        today = datetime.today()
        days_since_monday = today.weekday()
        this_monday = today - timedelta(days=days_since_monday)
        last_monday = this_monday - timedelta(days=7)
        last_friday = last_monday + timedelta(days=4)

        mask = (active['ìµœì´ˆë“±ë¡ì¼ì'] >= pd.Timestamp(last_monday)) & \
               (active['ìµœì´ˆë“±ë¡ì¼ì'] <= pd.Timestamp(last_friday))
        week_df = active[mask].sort_values('ìµœì´ˆë“±ë¡ì¼ì', ascending=False)

        week_label = f"{last_monday.strftime('%m/%d')}~{last_friday.strftime('%m/%d')}"

        lines = []
        lines.append(f"ğŸ“‹ DMF ì£¼ê°„ í˜„í™© ({week_label})")
        lines.append(f"{'='*30}")

        if len(week_df) == 0:
            lines.append("í•´ë‹¹ ì£¼ê°„ ì‹ ê·œ DMF ë“±ë¡ ì—†ìŒ")
        else:
            initial = int((~week_df['is_í—ˆì—¬']).sum())
            change = int(week_df['is_í—ˆì—¬'].sum())
            linked = int(week_df['has_ì—°ê³„ì‹¬ì‚¬'].sum())

            lines.append(f"ì´ {len(week_df)}ê±´ (ìµœì´ˆ {initial} / í—ˆì—¬ {change})")
            lines.append(f"ì—°ê³„ì‹¬ì‚¬ {linked}ê±´")
            lines.append("")

            for _, row in week_df.iterrows():
                reg_type = "ğŸ”µìµœì´ˆ" if not row['is_í—ˆì—¬'] else "ğŸŸ¡í—ˆì—¬"
                linked_mark = "âœ…" if row['has_ì—°ê³„ì‹¬ì‚¬'] else ""
                country = str(row.get('ì œì¡°êµ­ê°€', '')).replace('@', '/').strip()
                ingredient = str(row.get('ì„±ë¶„ëª…', ''))
                applicant = str(row.get('ì‹ ì²­ì¸', ''))

                lines.append(f"{reg_type} {ingredient}")
                lines.append(f"  {applicant} | {country} {linked_mark}")

            lines.append("")
            lines.append("ì¶œì²˜: ì˜ì•½í’ˆì•ˆì „ë‚˜ë¼ DMF ì‹¬ì‚¬ê²°ê³¼")

        os.unlink(excel_path)
        return "\n".join(lines)

    except Exception as e:
        logger.error(f"ì±„íŒ… ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return f"âŒ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„œë²„ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    transport = os.environ.get("MCP_TRANSPORT", "sse")

    print(f"ğŸš€ DMF Intelligence MCP Server ì‹œì‘")
    print(f"   Transport: {transport}")
    print(f"   Port: {port}")

    mcp.run(transport=transport, port=port)
